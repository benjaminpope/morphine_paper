%%
%% Beginning of file 'sample62.tex'
%%
%% Modified 2018 January
%%
%% This is a sample manuscript marked up using the
%% AASTeX v6.2 LaTeX 2e macros.
%%
%% AASTeX is now based on Alexey Vikhlinin's emulateapj.cls 
%% (Copyright 2000-2015).  See the classfile for details.

%% AASTeX requires revtex4-1.cls (http://publish.aps.org/revtex4/) and
%% other external packages (latexsym, graphicx, amssymb, longtable, and epsf).
%% All of these external packages should already be present in the modern TeX 
%% distributions.  If not they can also be obtained at www.ctan.org.

%% The first piece of markup in an AASTeX v6.x document is the \documentclass
%% command. LaTeX will ignore any data that comes before this command. The 
%% documentclass can take an optional argument to modify the output style.
%% The command below calls the preprint style  which will produce a tightly 
%% typeset, one-column, single-spaced document.  It is the default and thus
%% does not need to be explicitly stated.
%%
%%
%% using aastex version 6.3
\documentclass[modern]{aastex63}

%% The default is a single spaced, 10 point font, single spaced article.
%% There are 5 other style options available via an optional argument. They
%% can be envoked like this:
%%
%% \documentclass[argument]{aastex62}
%% 
%% where the layout options are:
%%
%%  twocolumn   : two text columns, 10 point font, single spaced article.
%%                This is the most compact and represent the final published
%%                derived PDF copy of the accepted manuscript from the publisher
%%  manuscript  : one text column, 12 point font, double spaced article.
%%  preprint    : one text column, 12 point font, single spaced article.  
%%  preprint2   : two text columns, 12 point font, single spaced article.
%%  modern      : a stylish, single text column, 12 point font, article with
%% 		  wider left and right margins. This uses the Daniel
%% 		  Foreman-Mackey and David Hogg design.
%%  RNAAS       : Preferred style for Research Notes which are by design 
%%                lacking an abstract and brief. DO NOT use \begin{abstract}
%%                and \end{abstract} with this style.
%%
%% Note that you can submit to the AAS Journals in any of these 6 styles.
%%
%% There are other optional arguments one can envoke to allow other stylistic
%% actions. The available options are:
%%
%%  astrosymb    : Loads Astrosymb font and define \astrocommands. 
%%  tighten      : Makes baselineskip slightly smaller, only works with 
%%                 the twocolumn substyle.
%%  times        : uses times font instead of the default
%%  linenumbers  : turn on lineno package.
%%  trackchanges : required to see the revision mark up and print its output
%%  longauthor   : Do not use the more compressed footnote style (default) for 
%%                 the author/collaboration/affiliations. Instead print all
%%                 affiliation information after each name. Creates a much
%%                 long author list but may be desirable for short author papers
%%
%% these can be used in any combination, e.g.
%%
%% \documentclass[twocolumn,linenumbers,trackchanges]{aastex62}
%%
%% AASTeX v6.* now includes \hyperref support. While we have built in specific
%% defaults into the classfile you can manually override them with the
%% \hypersetup command. For example,
%%
%%\hypersetup{linkcolor=red,citecolor=green,filecolor=cyan,urlcolor=magenta}
%%
%% will change the color of the internal links to red, the links to the
%% bibliography to green, the file links to cyan, and the external links to
%% magenta. Additional information on \hyperref options can be found here:
%% https://www.tug.org/applications/hyperref/manual.html#x1-40003
%%
%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
% added by DH
\usepackage{xspace}
\usepackage{}

\newcommand{\numax}{\mbox{$\nu_{\rm max}$}\xspace}
\newcommand{\Dnu}{\mbox{$\Delta \nu$}\xspace}
\newcommand{\dnu}{\mbox{$\delta \nu$}\xspace}
\newcommand{\muHz}{\mbox{$\mu$Hz}\xspace}
\newcommand{\teff}{\mbox{$T_{\rm eff}$}\xspace}
\newcommand{\logg}{\mbox{$\log g$}\xspace}
\newcommand{\feh}{\mbox{$\rm{[Fe/H]}$}\xspace}
\newcommand{\msun}{\mbox{$\mathrm{M}_{\sun}$}\xspace}
\newcommand{\mearth}{\mbox{$\mathrm{M}_{\oplus}$}\xspace}

\newcommand{\rsun}{\mbox{$\mathrm{R}_{\sun}$}\xspace}
\newcommand{\hipparcos}{\textit{Hipparcos}\xspace}
\newcommand{\gaia}{\textit{Gaia}\xspace}


\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand\kepler{\emph{Kepler}\,}
\newcommand\ktwo{\emph{K2}\,}

\definecolor{linkcolor}{rgb}{0.1216,0.4667,0.7059}


\usepackage{xcolor, fontawesome}
\definecolor{twitterblue}{RGB}{64,153,255}
\newcommand\twitter[1]{\href{https://twitter.com/#1 }{\textcolor{twitterblue}{\faTwitter}\,\tt \textcolor{twitterblue}{@#1}}}
\usepackage{amsmath}

%% Tells LaTeX to search for image files in the 
%% current directory as well as in the figures/ folder.
\graphicspath{{../notebooks/}}

%% Reintroduced the \received and \accepted commands from AASTeX v5.2
% \received{January 1, 2019}
% \revised{January 7, 2019}
% \accepted{\today}
%% Command to document which AAS Journal the manuscript was submitted to.
%% Adds "Submitted to " the arguement.
% \submitjournal{ApJ}

%% Mark up commands to limit the number of authors on the front page.
%% Note that in AASTeX v6.2 a \collaboration call (see below) counts as
%% an author in this case.
%
%\AuthorCollaborationLimit=3
%
%% Will only show Schwarz, Muench and "the AAS Journals Data Scientist 
%% collaboration" on the front page of this example manuscript.
%%
%% Note that all of the author will be shown in the published article.
%% This feature is meant to be used prior to acceptance to make the
%% front end of a long author article more manageable. Please do not use
%% this functionality for manuscripts with less than 20 authors. Conversely,
%% please do use this when the number of authors exceeds 40.
%%
%% Use \allauthors at the manuscript end to show the full author list.
%% This command should only be used with \AuthorCollaborationLimit is used.

%% The following command can be used to set the latex table counters.  It
%% is needed in this document because it uses a mix of latex tabular and
%% AASTeX deluxetables.  In general it should not be needed.
%\setcounter{table}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section outlines numerous optional output that
%% can be displayed in the front matter or as running meta-data.
%%
%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
\shorttitle{Kernel Phase and Coronagraphy with Automatic Differentiation}
\shortauthors{B. J. S. Pope et al.}
%%
%% You can add a light gray and diagonal water-mark to the first page 
%% with this command:
% \watermark{text}
%% where "text", e.g. DRAFT, is the text to appear.  If the text is 
%% long you can control the water-mark size with:
%  \setwatermarkfontsize{dimension}
%% where dimension is any recognized LaTeX dimension, e.g. pt, in, etc.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is the end of the preamble.  Indicate the beginning of the
%% manuscript itself with \begin{document}.

\begin{document}

\title{Kernel Phase and Coronagraphy with Automatic Differentiation}

\correspondingauthor{Benjamin J. S. Pope \twitter{fringetracker}}
\email{benjamin.pope@nyu}

\author[0000-0003-2595-9114]{Benjamin J. S. Pope}
\affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY 10003, USA}
\affiliation{Center for Data Science, New York University, 60 Fifth Ave, New York, NY 10011, USA}
\affiliation{NASA Sagan Fellow}

\author[0000-0003-3818-408X]{Laurent Pueyo}
\affiliation{Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD, 21218, USA}

\author[0000-0002-6171-9081]{Yinzi Xin}
\affiliation{Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA}

\author[0000-0001-7026-6291]{Peter~G.~Tuthill}
\affiliation{Sydney Institute for Astronomy (SIfA), School of Physics, The University of Sydney, NSW 2006, Australia}


%% Mark off the abstract in the ``abstract'' environment. 
\begin{abstract}
% optical imaging with aberrations
The accumulation of aberrations along an  optical path produces distortions and speckles in the resulting images, limiting the performance of cameras at high angular resolution. It is important to achieve the highest possible sensitivity to faint sources, using both hardware and data analysis software. While analytic methods are efficient, real systems are better-modelled numerically, but numerical models of complicated optical systems with many parameters can be hard to understand, optimize and apply.
% autodiff can make this practical for arbitrary optical systems
Automatic differentiation or `backpropagation' software developed for machine learning applications now makes calculating derivatives with respect to aberrations in arbitrary planes straightforward for any optical system.
% self cal - closure phase and kernel phase
We apply this powerful new tool to the problem of high-angular-resolution astronomical imaging. Self-calibrating observables such as the `closure phase' or `bispectrum' have been widely used in optical and radio astronomy to mitigate optical aberrations and achieve precise astrometry. Kernel phases are a generalization of closure phases valid in the limit of small phase errors.
% we demonstrate a simple example of the kernel of a monochromatic coronagraph
Using automatic differentiation, we reproduce existing kernel phase theory within this framework and demonstrate an extension to the case of a Lyot coronagraph, which is found to have self-calibrating combinations of speckles which are resistant to phase noise, but only in the very high wavefront quality regime. We apply this framework to reanalyze Palomar adaptive optics observations of the binary $\alpha$~Ophiuchi, finding consistency between the new pipeline and the existing standard.
%phase design
We present a Python package \textsc{morphine} that incorporates these ideas, with an interface similar to the popular package \textsc{poppy}, for optical simulation with automatic differentiation. These methods may be useful for designing improved astronomical optical systems by gradient descent.
\href{https://github.com/benjaminpope/morphine}{\color{linkcolor}\faGithub} % shamelessly borrowed from Luger!

\end{abstract}

%% Keywords should appear after the \end{abstract} command. 
%% See the online documentation for the full list of available subject
%% keywords and the rules for their use.
% \keywords{editorials, notices --- 
% miscellaneous --- catalogs --- surveys}


\section{Introduction} 
\label{sec:intro}
% optical imaging with aberrations
Many questions in astronomy and other sciences can only be answered with diffraction-limited high resolution imaging. The highest resolutions are typically achieved with the method of interferometry, in which waves detected at multiple receivers are combined physically or in post-processing to obtain the Fourier transform of the source intensity distribution \citep{vc34,zernike38}. Even in the case of a single telescope or camera, it is often nevertheless helpful to think of them as an interferometer composed of many sub-apertures which combine their signals directly onto a focal plane \citep[a `Fizeau interferometer':][]{fizeau1868}. In all of these cases, unknown path delays toward each receiver or subaperture are a dominant source of noise, causing `tip-tilts' of the final image position, distortions of the point spread function (PSF) from low-spatial-frequency aberrations, and clouds of `speckles' from high-spatial-frequency aberrations.

% self cal with closure phase
In order to correct for this, it is possible to use active hardware such as adaptive optics or delay lines; calibrating these errors with comparison to a reference star; or self-calibration, using the physics of the noise process to correct for it in post-processing.
In the recovery of object phase information, among the most longstanding techniques is that of self-calibration with `closure phases' \citep[introduced in the context of radio astronomy by][]{jennison58}, in which phases are summed around three interferometric baselines which form a closing triangle. The phase error terms local to each subaperture cancel, so that three low-signal-to-noise (SNR) baseline phases deliver one high-SNR observable. In a non-redundant array (one in which no baseline vector is repeated between different pairs of subapertures) of sufficient size, a large number of closure phases can be obtained which anchor image reconstruction with great precision. `Closure amplitudes' which are resistant to fluctuations in input amplitude or gain can also be obtained by a similar construction using four telescopes \citep{twiss60,blackburn20}. The closure phase is the argument of a quantity called the triple product or `bispectrum', and it has recently been shown from the perspective of invariant theory in algebraic geometry that for a wide class of problems limited by phase noise, knowledge of the mean of a signal, its power spectrum, and its bispectrum are necessary and sufficient for an optimal signal reconstruction \citep{bandeira17}.

On the other hand, for the case of direct imaging of high contrast companions with coronagraphs, analytic self calibrations such as those above are not yet known, and external calibration is necessary. The standard approaches to data analysis in coronagraphy rely on exploring a diversity of PSFs experimentally, constructing a basis covering some of the diversity in speckle patterns, and then subtracting out a linear combination of vectors in this basis from measured data \citep[e.g.][]{lafreniere07,soummer12,pueyo16}. Advantages can also be gained from angular differential imaging \citep[ADI;][]{marois06} and spectral deconvolution with wavelength \citep{sparks02}. In this paper we will extend our understanding of analytic self calibration to better include coronagraphs, so that we can add an additional layer of precision to exoplanet imaging calibration.

\subsection{Kernel Phases}

% introduce kernel phase idea
The kernel phase method is a way of extending closure phase from simple nonredundant arrays of telescopes to the densely-filled pupils of real telescopes. If we describe the propagation of phase and amplitude noise in terms of a matrix \citep{lannes1991}, we can obtain powerful generalizations to closure phases and amplitudes. We then write

\begin{equation}
    \mathbf{\Phi} = \mathbf{\Phi}_0 + \mathbf{A}_\phi \cdot \phi,
\end{equation}

\noindent where $\mathbf{\Phi}$ is a vector of observed phases on each baseline in the $u,v$ (focal plane Fourier domain), $\mathbf{\Phi}_0$ the true astrophysical phases, $\phi$ the phase noise at each point in the pupil plane, and $\mathbf{A}_\phi$ a transfer matrix from the pupil plane to the $u,v$ plane phases. A similar expression can be written for amplitudes \citep{pope16}.  Even for a redundant aperture such as a standard full telescope pupil, for sufficiently small phase perturbations ($<< 1~\text{rad}$), error propagation to the focal plane Fourier phases is still approximately linear: this is simply a Taylor expansion to first order of the nonlinear phase transfer operation, in which $\mathbf{A}_\phi$ is the Jacobian matrix of partial derivatives $\partial\Phi_j/\partial\phi_k$. For a single focal plane imaging system this operator $\mathbf{A}_\phi$ can be determined analytically for a given discrete pupil model. 

\citet{martinache10} introduced the idea of `kernel phase' to generalize this idea to a redundant aperture. In this case, the propagation of phase noise from the pupil to baselines is no longer linear, but in the limit where aberrations are small it can be linearized. While in this case closure phases no longer exactly cancel out the contributions of aberrations $\phi$, nevertheless in general a left kernel operator $\mathbf{K}$ can be found via singular value decomposition (SVD) that annihilates $\mathbf{A}_\phi$, such that

\begin{equation}
        \mathbf{K}\cdot\mathbf{A}_\phi = 0
\end{equation}

\noindent and therefore we can find self-calibrating kernel phases $\mathbf{K}\cdot\mathbf{\Phi}$ which are immune to phase noise to linear order:

\begin{align}
    \mathbf{K}\cdot\mathbf{\Phi} &= \mathbf{K}\cdot\mathbf{\Phi}_0 + \mathbf{K}\cdot\mathbf{A}_\phi\cdot\phi \\
    &= \mathbf{K}\cdot\mathbf{\Phi}_0.
\end{align}

Meanwhile, the phases in the complementary space to the kernel space have the opposite property, that they are especially sensitive to input phase aberrations, and for appropriate apertures can be used for wavefront sensing from the image domain \citep{martinache13,pope14}.

The kernel phase method has been applied to space-based data from the \textit{Hubble Space Telescope} NICMOS camera \citep{pope13,laugier19,martinache20}; ground-based data from the Palomar 200-Inch adaptive optics (AO) equipped Pharo camera \citep{palomar,martinache20}, the Large Binocular Telescope \citep{sallum15}, the VLT/NACO camera \citep{kammerer19}, MagAO \citep{sallum19b}, and explored theoretically for ground- and space-based telescopes \citep{ireland13,martinache11,sallum19a,ceau19}.

The kernel phase method relies on a Taylor expansion of the optical propagation, which is possible to do analytically. But many systems in reality cannot be treated this way - for example, problems involving diffraction between multiple planes like in coronagraphs. We shall see in the following that automatic differentiation can supply derivatives for arbitrary numerically-simulated imaging systems, extending self-calibration to a wider class of instruments and also offering new opportunities for optical design and optimization.

\subsection{Automatic Differentiation}
% autodiff/backpropagation - history & citations
The practical use of neural networks in machine learning applications is dependent on the efficient calculation of analytic gradients of often very complicated composite functions, for example the matrix operations composed with nonlinear activation functions that are seen in neural networks \citep{lecun15}. This problem is usually referred to as algorithmic differentiation, automatic differentiation or `autodiff', and is solved simply by the chain rule.
Autodiff is available in many implementations, such as the Python packages \textsc{TensorFlow} \citep{tensorflow2015}, \textsc{theano} \citep{theano}, \textsc{PyTorch} \citep{pytorch}, \textsc{autograd} \citep{autograd}, \textsc{jax} \citep{jax}, and many packages in the Julia language \citep{julia}. The reverse-mode autodiff or `backpropagation' algorithm \citep{linnainmaa1970,lecun1988theoretical} has made this practical for neural networks, but it is typically most-useful in cases where the output dimensionality is much smaller than the input, such as neural networks; forwards-mode autodiff, on the other hand, is usually better in the case where the output is of higher dimension than the input. For optics problems, both of these can be the case - for example, for optimization, backpropagation is usually the best approach, but for kernel phase analysis, forwards mode is better suited.

% optics is linear and nonlinear relations between quantities eg phase consist entirely of elementary operators that can be differentiated like in a neural network
In simulating physical optics, we normally consider the complex electric field on a 2D plane, which is pixelized and then flattened to a 1D vector.
Optical propagation then consists of a series of Fourier (or  Fresnel) transforms mapping between planes, and matrix or element-wise multiplications by phase and amplitude screens in those planes. Indeed, for practical purposes in astronomy and imaging science generally, optical propagation through a whole system is generally a linear operation that could be written as a single (large) matrix multiplication. However quantities of interest are usually not specified as real and imaginary electric field components, but rather as amplitudes and phases, so that the relations between (for example) input and output phases is in general nonlinear. Finding the derivatives of $u,v$ phase with respect to pupil aberrations is therefore an ideal problem for autodiff.

The analogy between the operations of optics and deep neural networks is so strong that not only have autodiff packages been used to simulate photonic systems \citep[e.g.][]{hughes18}, photonic systems have in fact been used as analog computers implementing neural networks for machine learning \citep{hughes19,guo19}. 

Several groups have applied autodiff to areas of optical science relevant to astronomy. Autodiff has been applied fruitfully to geometric optics or ray-tracing \citep[e.g.][]{werner2012,sutin16}, which is important in astronomy for understanding gravitationally-lensed systems. \citet{chianese19} and \citet{morningstar19} have applied this method to integrating differentiable forwards models of gravitational lensing with neural networks for image analysis. Autodiff methods have also been applied for image reconstruction from interferometric data, including gravitationally-lensed systems \citep{morningstar18} and protoplanetary disks \citep{czekala19}.

The \textsc{DeepOptics} project \citep{sitzmann2018} has used autodiff to optimize `computational cameras'. Building their model in \textsc{TensorFlow}, they couple a physical optics simulation, detector simulation, and a deconvolution post-processing stage for a total end-to-end imaging simulation. Where normally you might optimize some heuristic of the PSF (such as the full width at half maximum), this makes it possible to jointly optimize hardware and software with respect to figures of merit of the overall system such as final resolution or depth of field. Some designs arrived at in this way are exotic: for example, super-resolution is achieved by finding a lens with three off-centre Fresnel-lens components focusing to three separate spots, which the deconvolution stage shifts and stacks. Because it is built in \textsc{TensorFlow}, the diffraction simulation can be incorporated as a `physical layer' in neural network applications in microscopy, for example for optimizing hardware and software for image classification \citep{muthumbi19}, or with reinforcement learning for adaptively learning sample illumination \citet{chaware19}.

An approach similar to \textsc{DeepOptics} is likely to be extremely valuable in designing, for instance, pupil masks for coronagraphy \citep[e.g.][]{guyon03,carlotti11} or for diffractive-pupil astrometry \citep[e.g.][]{guyon12,tuthill18}. 

Close to the topic of this paper, autodiff has been applied to the problem of phase retrieval \citep{jurling14,paine19}, inferring a wavefront from a PSF. In this context, a key advance of autodiff over previous methods is that we can trivially account for pixel sampling/binning and detector nonlinearity. These will be important issues when considering that the JWST mid-infrared imager MIRI will have significant detector nonlinearity \citep{rieke15}, or where we may wish to look at saturated sources.  While they do not address more complex optical systems, this method may be straightforwardly applicable to sensing non-common-path errors in coronagraphic images. While \citet{jurling14} derive analytic expressions for many optically-relevant operations, machine-learning software that has become available since then have significantly widened the range of options and introduced more user-friendly APIs. These approaches have been taken up outside of optical imaging, for example in X-ray coherent diffractive imaging \citep{kandel19,nashed19} and nanotomography \citep{Dueaay3700}.

Rather than using these autodiff gradients for optimization, in this paper we use them to understand optical systems and the information they propagate.
In the following we will show how autodiff can reproduce the existing state of the art in kernel phase, and demonstrate a way forward using autodiff to extend the kernel phase idea to coronagraphic instruments.

\section{Simulations}
\label{sec:method}

For our forwards model, we adapt the popular physical optics library \textsc{poppy} \citep{poppy}, with the goal of compatibility with existing simulations built on \textsc{poppy} such as \textsc{WebbPSF} \citep{webbpsf}. We use the matrix Fourier transform mode to avoid using the FFT \citep{soummer07}, as we can more easily generate arbitrary image sampling this way. We have adapted the low-level features of \textsc{poppy} to use the Google autodiff library \textsc{jax} \citep{jax} in place of \textsc{NumPy}, and to distinguish it from the original version we call this new \textsc{poppy} derivatives library \textsc{morphine}. %The \textsc{NumPy}-like API of \textsc{jax} is chosen so that astronomers can painlessly integrate \textsc{morphine} with their existing code, but we note that a \textsc{DeepOptics}-like approach using \textsc{TensorFlow} may be preferable in the longer term for integration with neural networks. 

This has several advantages already over analytic methods for kernel phase. \textsc{morphine} can calculate monochromatic or polychromatic PSFs: the polychromatic capability allows us to explicitly construct broadband kernel phase operators. It is also possible to take derivatives with respect to wavefronts specified in bases other than the pixel basis, for example Zernike or hexike modes, as we shall discuss in Section~\ref{zernike}.

\subsection{Simple Diffraction}
\label{sec:simple}

First we want to reproduce the basic kernel phase calculations in this new model. We propagate monochromatic 2.0\,$\mu$m light through a 2.0\,m diameter circular pupil onto a detector with a 20\,mas/pixel scale and 4\,arcsec field of view. The pupil and $u,v$ are each calculated on a 64x64 grid. We evaluate the Jacobian of the $u,v$ phases with respect to the input pupil phases using forwards-mode autodiff and then evaluate this Jacobian at zero phase to get our $\mathbf{A}$ matrix\footnote{\href{https://github.com/benjaminpope/morphine/blob/master/notebooks/morphine_u,v.ipynb}{github.com/benjaminpope/morphine/blob/master/notebooks/morphine\_u,v.ipynb}}. On a laptop computer this takes a few minutes processing time. Memory usage is the main overhead: in practice on a laptop with 16GB RAM, we are limited to grids no larger than 128x128. Demand on computational resources presents a major limitation to widespread application; in future this may be overcome by more efficient refactoring of the code, or simply by doing calculations on clusters with very large RAM allocations.

Although it is inefficient to calculate this full Jacobian with respect to a densely-pixelized basis for the wavefront in the pupil plane, we do so here for completeness. In practical cases, aberrations are typically dominated by low-order modes and we could consider the Jacobian only with respect to (for example) some much smaller number of Zernike modes. Reducing the input dimensionality like this would have significant advantages in memory usage for forwards-mode autodiff.

In Figure~\ref{kernel_jacobian} we display the results of our Jacobian calculation for a set of highlighted pupil samples and how they influence the phases in the $u,v$ plane. 

The results are similar to Figure~1 of \citet{martinache10}, consisting of the sums of translated positive and negative copies of the pupil aperture. Phase offsets outside the support of the pupil have identically zero derivative in the $u,v$ plane as expected. There is a greater magnitude in the derivative at longer baselines compared to the flat maps in \citet{martinache10} because we are rolling together the phase transfer $\mathbf{A}$ matrix and the redundancy matrix $\mathbf{R}$, and short baselines are much more redundant than long ones.

We calculate the singular values of this matrix (restricted to the support of the pupil) by SVD (Figure~\ref{fig:svd}), finding a sharp cutoff as expected, separating a subspace of kernel phases from phases contaminated by noise from the aberrations. In the nonsingular space, a selection of pairs of corresponding modes in the pupil and $u,v$ plane are displayed in Figure~\ref{nonsingular_modes}, and a selection of kernel phase modes in the $u,v$ plane are shown in Figure~\ref{kernel_modes}. These illustrate how at the edges of the pupil/long baselines there is extra noise. Because of the limited field of view, noise from outside the pupil or optical transfer function (OTF) is convolved inside, and large elements in the transfer matrix can dominate parts of the SVD. For numerical stability we have therefore excluded the very longest baselines in calculating kernel phases, but it would be preferable to use a more robust SVD that is tolerant of outliers. This is not a feature of the autodiff pipeline or \textsc{morphine}, but also of real data. Depending on the field of view of the simulated images, for the same pupil and $u,v$ sampling there can be slight differences in the autodiff-calculated kernel phases because of this effect. The normal analytic kernel phase derivation assumes an infinite field of view, but sees data with a finite field of view in which these window effects are apparent. %We need to account for the introduction of noise from outside the OTF to correctly calculate kernel phases, as the normal formalism is exact only in the limit of an infinite field of view. 

% \footnote{The OTF is the autocorrelation of the pupil, and is in this case also a circle. Its support is calculated by calculating a $u,v$ forwards model with zero phase offset and making an amplitude-threshold mask.}
\begin{figure}
\plotone{jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for monochromatic 2$\mu$m diffraction from a 2.0\,m diameter circular pupil. In each pair of images, on the left is the pupil, with a red dot highlighting a selected pixel; on the right is a map of the derivative in the $u,v$ plane with respect to the phase at this point in the pupil. We see the same maps as in Figure~1 of \citet{martinache10}. \label{kernel_jacobian}}
\end{figure}

\begin{figure}
    \plotone{kerphi_singular.pdf}
     \caption{Log-scale plot of the singular values of the phase transfer matrix plotted against index ordered by decreasing singular value for simple monochromatic diffraction (blue), 20\% bandwidth (green). Singular values are normalized to the first singular value. In both cases, there is a sharp cutoff separating significant singular values from a subset within machine precision of zero. The vectors corresponding to these approximately zero singular values span the null space of the phase transfer operator, and correspond to kernel phases.}
    \label{fig:svd}
\end{figure}

\begin{figure}
\plotone{nonsingular_modes_mono.pdf}
\caption{Pairs of nonsingular vectors in the pupil and $u,v$ planes from the SVD of the Jacobian in ~\ref{kernel_jacobian}. Some of these orthonormal basis vectors resemble Zernike modes, and all show some ringing structure at the edges of the pupil and OTF support.
\label{nonsingular_modes}}
\end{figure}

\begin{figure}
\plotone{kernel_modes_mono.pdf}
\caption{Some kernel phase maps - singular vectors in the $u,v$ plane from the SVD of the Jacobian in ~\ref{kernel_jacobian}. There is little apparent structure in these.
\label{kernel_modes}}
\end{figure}

We have also repeated the above calculations for light with a $20\%$ fractional bandwidth\footnote{\href{https://github.com/benjaminpope/morphine/blob/master/notebooks/morphine_u,v_broadband.ipynb}{github.com/benjaminpope/morphine/blob/master/notebooks/morphine\_u,v\_broadband.ipynb}}, with a uniform spectrum sampled ten times from $1.8\,\mu\text{m}$\,---\,$2.2\,\mu\text{m}$. The results are very similar, except that the Jacobian maps equivalent to Figure~\ref{kernel_jacobian} are slightly blurred. In the shape of the singular value curve between the broadband and monochromatic cases, a qualitatively similar behaviour is found, although the broadband case has slightly fewer kernel phases and a flatter roll-off.

\subsection{$\alpha$~Ophiuchi}
\label{sec:palomar}

We now apply the new kernel phase formalism to real data: the A-star $\alpha$~Ophiuchi. It was observed with the Palomar~200-Inch telescope, using the extreme adaptive optics system PALM-3K and the PHARO camera. These data were first analyzed by \citet{palomar}, but \citet{martinache20} showed that there was an error in the pupil model used for the original analysis: the pupil was in fact rotated 2 degrees. Using a more accurate pupil model and the updated `xara' kernel phase code, \citet{martinache20} obtained astrometry of separation $\rho = 123.5 \pm 2.9$~mas, position angle $\theta = 86.5 \pm 0.2$~degrees, and contrast $c = 25.1 \pm 1.1$. We therefore seek to recreate this new analysis using autodiff.

We first build a high resolution model of the PHARO pupil using the same code as \citet{martinache20}, and bin it down to a $64\times64$ pixel grid so that pixel values $\in [0,1]$ indicate the fraction of the telescope aperture filling that binned pixel. We then propagate monochromatic 2.145\,$\mu$m light through this onto a $128\times128$-pixel image plane, and use a matrix Fourier transform to map this onto a $u,v$ plane of the same size. We differentiate this using the forwards mode autodiff as above, obtaining the Jacobian shown in Figure~\ref{pharo_jacobian}, and calculate a kernel phase transfer matrix.

\begin{figure}
\plotone{pharo_jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for the PHARO pupil in $K$-band. In each pair of images, on the left is the PHARO pupil, with a red dot highlighting a pupil sample; on the right is a map of the derivative in the $u,v$ plane with respect to phase at that pupil sample. We see the same maps as in Figure~1 of \citet{martinache10}. \label{pharo_jacobian}}
\end{figure}

We then extract kernel phases from both $\alpha$~Oph and a point source calibrator $\epsilon$~Her using a version of \textsc{xara} modified to use the \textsc{morphine} matrix FT. Following \citet{martinache20}, we choose as our observables the median kernel phases across all 100 exposures for each, and the standard error of the mean as our base uncertainty on each. To calibrate the kernel phases, we simply subtract those of the calibrator from $\alpha$~Oph and add their uncertainties in quadrature. To see the effect of the known optical `ghost' (introduced by an unwanted reflection from the neutral density filter used to observe bright stars), we calculate kernel phase `colinearity' maps as in \citet{martinache20}, shown in Figure~\ref{colinearity}. In these maps we can see that the filter ghost shows up strongly as a false binary in the uncalibrated kernel phase maps, but calibrated kernel phases easily remove this and reveal the tight $\alpha$~Oph binary. 

In \citet{martinache20} a large error term was added in quadrature in order to account for additional noise in the data unexplained by the diversity over exposures and uncalibrated by the kernel phase model. Using nonlinear least squares to fit the calibrated data, we also find that the best-fitting binary model has a high $\chi^2$. We therefore follow \citet{martinache20} and determine a value for error added in quadrature to make the reduced $\chi^2 = 1.0$. \textcolor{red}{What value?}

\begin{figure}
\plotone{colinearity_alphaoph.pdf}
\caption{Kernel phase colinearity maps showing the normalized dot product of a binary model (pale is a better match) to the kernel phase signals from uncalibrated $\alpha$~Oph data (left), the calibrator $\eps$~Her (middle), and calibrated data (right). They closely resemble the maps in Figure~8 of \citet{martinache20}. We can see that in uncalibrated data the filter ghost is clearly visible, but in calibrated data we extract the $\alpha$~Oph binary with no effect from the ghost. \label{colinearity}}
\end{figure}

We then use Markov Chain Monte Carlo \citep{metropolis53} to sample from the posteriors assuming Gaussian likelihoods, using the \texttt{emcee} affine-invariant ensemble sampler \citep{emcee}. We obtain binary parameters of separation $\rho = 120.2 \pm 1.2$~mas, position angle $\theta = 86.2 \pm 0.3$~degrees, and contrast $c = 24.4 pm 0.6$: all well within 1$\sigma$ of the \citet{martinache20} figures. We likewise use \texttt{emcee} to sample from the likelihood using the \citet{martinache20} code. Posteriors for both inferences are shown in Figure~\ref{comparison_posterior}.

\begin{figure}
\plotone{comparison_posterior.pdf}
\caption{Posterior distributions for the binary parameters of $\alpha$~Ophiuchi as determined by the autodiff pipeline (black) and the \citet{martinache20} implementation (blue). \label{comparison_posterior}}
\end{figure}

% In order to investigate this discrepancy, we generated a grid of forwards models. Using the same code used to produce the kernel phase autodiff model, we generated input wavefronts with 20 Zernike modes of aberrations, each with random amplitudes normally-distributed with 15\,nm standard deviation, for a total peak-to-peak amplitude of 206\,nm. These were then shifted and added to simulate a range of binaries at different configurations and contrasts, and both the \citet{martinache20} pipeline and the autodiff pipeline were used to retrieve their parameters. The results are shown in Figure~\ref{method_comparison_ensemble}. The pipelines achieve broadly comparable performance on these simulations, with the \citet{martinache20} method being slightly better at closer separations and higher contrasts and autodiff performing marginally better at larger separations. 

In order to investigate the effect on both pipelines of wavefront errors leaking in, we generated a cube of 1000 PSFs with 20 Zernike modes of aberrations, this time with 20\,nm standard deviation, for a total peak-to-peak wavefront amplitude of $295\pm 100$\,nm. We then retrieved the system parameters with \texttt{emcee} for the cube, taking as our observables the median kernel phases and the standard error of the mean over the ensemble (posterior in Figure~\ref{comparison_posterior_sim}; and also frame-by-frame using least squares (displayed in Figure~\ref{comparison_posterior_sim_cube}. For a simulated binary with fiducial $\rho = 125$\,mas, $\theta=86^\circ$, and $c = 25$, there is no sign of the large systematic difference between the methods as seen in real data. Both methods, whether frame by frame or on average, retrieve the true parameters with similar accuracy and precision. %Whatever systematic this is may be treated differently by these two pipelines, and may need to be a subject for future work.

% \begin{figure}
% \plotone{method_comparison_ensemble.pdf}
% \caption{Comparison of \citet[][blue stars]{martinache20} and autodiff (orange dots) kernel phase pipelines on simulated data, as a function of input contrast (left) and separation (right). When inspected, the samples with worse separation error after both pipelines are those at higher contrasts. Uncertainties are omitted for clarity, and because they are poorly defined in this context. \label{method_comparison_ensemble}}
% \end{figure}

% \begin{figure}
% \plotone{comparison_posterior_sim.pdf}
% \caption{Comparison of \citet[][blue linetype]{martinache20} and autodiff (black) kernel phase pipelines on simulated data with true parameters $\rho = 125$~mas, $\theta = 86^\circ$, $c=25$. We generate a cube of 1000 mock datasets using a 64-pix pupil model and Zernike aberrations as described in Section~\ref{sec:palomar}, and the observables used are the median and standard error of the mean of each kernel phase across this ensemble. Both datasets retrieve the true parameters very precisely, though with small systematic offsets, which are slightly larger for the autodiff method than for classic kernel phases. \label{comparison_posterior_sim}}
% \end{figure}


\begin{figure}
\plotone{comparison_posterior_sim_cube.pdf}
\caption{Comparison of \citet[][blue linetype]{martinache20} and autodiff (black) kernel phase pipelines on simulated data with true parameters $\rho = 125$~mas, $\theta = 86^\circ$, $c=25$. We generate a cube of 1000 mock datasets using a 64-pix pupil model and Zernike aberrations as described in Section~\ref{sec:palomar}. The corner plot displays the parameters retrieved using a simple least squares fit applied to each individual frame. The methods have very similar distributions centred tightly on the true value. \label{comparison_posterior_sim_cube}}
\end{figure}

In order to establish the accuracy of both pipelines, we conducted an injection test. We took the first frame of the $\eps$~Her datacube as our `data' and use a subpixel Fourier shift to create a mock binary at a position angle of $90^\circ$, contrast 25, and a range of separations from 90-300~mas. We then used least squares to fit these data using both models (initialized at the true values), determined in each case an error to add in quadrature to make reduced $\chi^2=1.0$, and re-ran the least squares fit with new data, saving the best-fit parameters and uncertainties taken from the square root of the diagonal elements of the inverse covariance matrix. The results are shown in Figure~\ref{injection_recovery}. Both methods perform comparably well, achieving results reasonably close to the injected values. Systematics in all three parameters, of amplitude comparable to the $1\sigma$ statistical uncertainties, vary smoothly and similarly as a function of input separation. The autodiff pipeline performs somewhat better at smaller separations in all three parameters. This indicates that both kernel phase pipelines do a good overall job at binary imaging with PHARO, but that as noted by \citet{martinache20} not all sources of uncertainty are well-understood or calibrated.

\begin{figure}
    \plotone{injection_recovery_pharo.pdf}
     \caption{Injection recovery results for PHARO using both the \citet{martinache20} and autodiff kernel phase models. From top to bottom we show the error in the recovered separation, the recovered position angle, and the recovered contrast as a function of injected separation, with $1\sigma$ uncertainty errorbars. Both methods show similar performance, with small systematic errors of comparable size to their statistical uncertainties.}
    \label{injection_recovery}
\end{figure}

% In numerical experiments, subpixel mismatch in Fourier transform coordinates or even Fourier centering convention could cause mismatches between simulation parameters and retrievals at around the scale of the discrepancy between the two methods.  These results are in line with the \citet{martinache_habilitation} conclusion that inexact Fourier sampling contributes significant systematic noise to kernel phases. The final version used for the autodiff pipeline uses the exact optical model used to generate the data, and a differentiable version of the exact $u,v$ transform implementation used in \textsc{xara}; we do not believe this to be the main cause of the small discrepancy between autodiff and conventional parameters, but it does illustrate that model mis-specification may be a contributing factor.

\subsection{Coronagraphy}
\label{sec:coronagraph}

% coronagraphs, speckles etc
It is desirable to find a priori self-calibration schemes for high-angular-resolution, high-contrast imaging systems more generally, including not merely nulling interferometers but optically complex coronagraphs intended to suppress light in a region around a target star. One particularly interesting extension of the kernel phase idea is the `kernel nuller' concept \citep{martinache18}, in which the aberration transfer matrix and kernel operator idea is applied to the output of a nulling interferometer. 

For arbitrary systems, to generate our Taylor expansion, we wish to be able to take the Jacobian of arbitrary features of the final speckle pattern with respect to phases in the input wavefront or in intermediate planes. This could then be used in postprocessing to generate `kernel speckles' resistant to noise, or in wavefront control for adaptive optics, or for digging `dark holes' to search for high contrast companions \citep{malbet95}.

Arbitrary-order Taylor series expansions for a PSF with respect to small phase perturbations can be derived analytically for a telescope with an arbitrary pupil brought to a single focus \citep{bloemhof01,anand02,perrin03}. This expansion breaks down for more complex optical systems. The PSF of a coronagraphic imager far from the occulted region is very similar to that of the primary PSF of the telescope, but close to the inner working angle it is significantly affected by the occultation and especially strongly by low-order wavefront errors. This is likewise an issue where detector nonlinearity and saturation significantly distort the PSF. While the analytic series expansion is no longer applicable in these regimes, using matrix Fourier transforms and skipping saturated pixels or pixels inside the coronagraphic inner working angle has shown promise for pushing kernel phase beyond its conventional limitations \citep{laugier19b}, as have generalizations that exploit angular differential imaging for a further level of calibration \citep{laugier20}.

Here we will apply the formalism demonstrated above for simple diffraction to a new case: coronagraphy. We will find that the exact same approach generates an analogous modal decomposition and kernel observables.

We consider a very simple Lyot coronagraph \citep{lyot30}, exploiting the ability of \textsc{morphine} to analyze systems that would otherwise be too computationally demanding. We choose a 1\,$\mu$m wavelength, and 1\,m diameter pupil sampled on a $96\times96$ grid. The central $4 \lambda/D$ region of the resulting PSF is blocked out with an on-axis focal plane stop (occulter), and the light is then propagated to a second pupil plane using an FFT rather than a matrix FT, following standard \textsc{poppy} practice. This imposes tougher memory constraints, and in future may be replaced with an MFT. A Lyot stop (an iris mask undersized 10\% relative to the input pupil) is then imposed, and the light propagated to a final focal plane sampled on a 50\,mas pixel scale grid with a 4~arcsec field of view. Aside from the coarse gridding, this is intentionally identical to one of the standard test and verification examples supplied with \textsc{poppy}\footnote{\href{https://github.com/mperrin/poppy/blob/master/notebooks/MatrixFTCoronagraph_demo.ipynb}{github.com/mperrin/poppy/blob/master/notebooks/MatrixFTCoronagraph\_demo.ipynb}}. The PSF produced has a dark coronagraphic hole in the middle, and beyond an inner working angle around this hole has a pattern of diffraction rings.

Again using \textsc{jax}, we calculate the Jacobian of this PSF with respect to the input wavefront, evaluated at uniform-zero phase, which again takes a few minutes on a laptop. The previous approach has been to directly propagate through the end to end simulation for a grid of small perturbations in the input plane \citep{falco}, whereas this is now taken care of by autodiff. The results are displayed in Figure~\ref{speckle_jacobian} in a similar format to Figure~\ref{kernel_jacobian}. Pixels far out in the PSF correspond to sinusoidal modulation of the input wavefront as expected, and this is symmetric about the origin. On the other hand, pixels near the inner working angle where the effects of the coronagraph are evident correspond to more complex modes in the pupil, also containing contributions from the ring obscured by the Lyot stop when the pupil is re-imaged. 

Calculating the SVD of this Jacobian (again restricted to the support of the primary pupil) we see a decline to very small singular values, albeit not as steep as earlier for the simple imaging case. The ordered singular value curve is displayed in Figure~\ref{fig:svd_coronagraph}. The nonsingular modes form a basis, like the Zernike basis, that maps between aberration patterns in the pupil and the speckle modes they generate. Some pairs of nonsingular modes in the pupil and image plane are shown in Figure~\ref{nonsingular_corona}

\begin{figure}
\plotone{speckle_jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for a simple Lyot coronagraph. In each pair of images, on the left is the speckle pattern, with a red dot highlighting the selected pixel; on the right is a map of the corresponding pixel's derivative with respect to phase over the pupil. Speckles far from the central dark hole correspond simply to sinusoids across the pupil, while speckles near the inner working angle correspond to more complicated patterns. \label{speckle_jacobian}}
\end{figure}


\begin{figure}
    \plotone{corona_singular.pdf}
     \caption{Log-scale plot of the singular values of the phase transfer matrix versus index for the coronagraph simulation in Section~\ref{sec:coronagraph}. Singular values are normalized to the first singular value.}
    \label{fig:svd_coronagraph}
\end{figure}

\begin{figure}
\plotone{nonsingular_modes_corona.pdf}
\caption{Pairs of nonsingular vectors in the pupil and image planes from the SVD of the coronagraph Jacobian in~\ref{speckle_jacobian}.
\label{nonsingular_corona}} 
\end{figure}

% \begin{figure}
% \plotone{kernel_modes_corona.pdf}
% \caption{Some kernel speckle maps - damped (nearly-singular) vectors in the image plane from the SVD of the coronagraph Jacobian in~\ref{speckle_jacobian}. There is little apparent structure in these except for weak patterns around the occulted region.
% \label{kernel_corona}}
% \end{figure}

% As the singular values here do not drop exactly to zero, we verify numerically that these really do span a kernel space of the coronagraph operation. We therefore calculate PSFs corresponding to each wavefront shape in the pupil domain SVD space, for peak amplitude 0.001~rad, 0.01~rad, and 0.1~rad. In Figure~\ref{fig:mads}, we show the median absolute deviation between an unaberrated reference PSF calculation and these simulations, as a function of SVD index. Dotted lines show where the normalized singular values drop below 0.5 (the beginning of the `roll-off' region), $10^{-4}$ (the kernel), and the beginning of modes under the Lyot stop. 

% For both aberration amplitudes, the effects of these aberrations begin to drop sharply at the roll-off and again at the steeper drop off beginning the kernel proper, and this effect is more pronounced for the smaller aberrations. This behaviour is most likely due to the breakdown of linearity for larger phases.

% \begin{figure}
%     \plotone{coronagraph_mad.pdf}
%     \caption{Median absolute deviation as a function of singular value index, between a reference PSF with no aberration and a PSF calculation with $10^{-3}$~rad (blue), $10^{-2}$ rad (green), and $10^{-1}$ peak phase (orange), and the shape of the corresponding singular vector of the pupil domain. Dotted lines show index 405 where the normalized singular values drop to 0.5 in the `roll-off' region; 441, where the singular values drop below $10^{-4}$ (our proposed kernel space); and index 958 where they hit the flat region corresponding to modes under the Lyot stop.}
%     \label{fig:mads}
% \end{figure}

% \begin{figure}
% \plotone{speckle_jacobian_zernike.pdf}
% \caption{A representation of the Jacobian determined by \textsc{jax} for a simple Lyot coronagraph using a Zernike basis of 200 modes to represent wavefront error. In each pair of images, on the left is the speckle pattern, with a red dot highlighting the selected pixel; on the right is a map of the corresponding pixel's derivative with respect to phase over the pupil. We expect that speckles far from the central dark hole will correspond to sinusoids across the pupil, but in the Zernike basis these appear significantly distorted. \label{speckle_jacobian_zernike}}
% \end{figure}

For the coronagraph under consideration, the regime over which the linear approximation applies may strictly limited. To illustrate this, we take one of the sinusoidal ripples which are the columns of the Jacobian in Figure~\ref{speckle_jacobian}, propagate this through a full optical simulation, and take the difference with respect to an unaberrated PSF. In Figure~\ref{corona_nonlinearity}, we see the effects of a sinusoidal phase ripple in the nearly-exact linear regime with a 0.1~nm amplitude, and a with a small but non-negligible 5.0~nm amplitude. In the linear regime and where the phase ripple is very small, we see that the speckle is positive on one side of the PSF and negative on the other corresponding closely with expected behavior from the Jacobian. On the other hand increaasing the amplitude of the phase ripple is even to  5 nanometres is enough to change the outcome completely. We see from the figure that the speckles are now both positive: a radical switch in behavoir indicating the quadratic term in the Taylor series has become dominant. This quadratic term involves a rank-3 tensor, of the second partial derivatives of each pixel with respect to the wavefront -- and there is no equivalent of a kernel operator for tensors of this dimension. The use of kernel phases as robust observables will therefore fail in this case, though we suggest that future work may search for a higher-dimensional kernel manifold. 

We have therefore shown that under the same linear assumptions previously applied to yield kernel phases, analogous self-calibrating observables also exist for propagation through more complex optical systems such as coronagraphs. However for the example configuration explored, the rapid onset of non-linear response indicates they may be of limited practical applicability to coronagraphic observations except in the extremely high-wavefront-quality regime. Sub-nanometre wavefront precision may nevertheless be achieved in future large space telescopes with high-order deformable mirrors.

\begin{figure}
\plotone{corona_nonlinearity.pdf}
\caption{The effect of a sinusoidal phase ripple on the speckle pattern of the coronagraph in Section~\ref{sec:coronagraph}. Left: sinusoidal phase pattern. Centre left: linear transfer map applied to the sinusoidal phase pattern, showing alternating positive and negative speckles on either side of the centre of the PSF. Centre right: the difference between a full optical simulation with an 0.1~nm amplitude phase ripple with respect to an unaberrated PSF, clearly close to the linear case. Right: the same difference simulation but with a 5~nm amplitude ripple, showing positive speckles on both sides of the detector - the quadratic term. \label{corona_nonlinearity}}
\end{figure}

\subsection{Zernike Basis}
\label{zernike}

Because taking the Jacobian of one large pixel grid by another is expensive in terms of memory, it is desirable to bring down the dimensionality of either the input or target space. One way to do this is to use a Zernike basis to represent the wavefront \citep{zernike34}. One advantage of this is that we can examine only up to a certain order in Zernike polynomials if we believe that wavefront errors are negligible below a certain spatial scale. We can then differentiate just with respect to Zernike coefficients, which is much more computationally efficient and allows us to run simulations on grids that are many times larger than otherwise. Similar bases (eg the `hexike' basis) can be constructed for arbitrary non-circular telescope apertures.

We have re-run the simple diffraction simulation from Section~\ref{sec:simple} with 200 Zernike modes on a $256\times256$ grid, and the coronagraph from Section~\ref{sec:coronagraph} on a $128\times128$ grid using 300 Zernike modes. 
The Jacobian derived from this basis for simple diffraction is an excellent approximation to the full calculation on a grid. Given that in problems such as HST data analysis we believe that PSF variations are dominated by low-order modes \citep{pope13}, this allows us to calculate a larger kernel space with a more accurate pupil model than has previously been possible. 

While it is a huge advantage in simulation speed and fidelity, this basis does not accurately represent the high-spatial-frequency sine waves corresponding to speckles far from the core of the PSF. Nevertheless, it does an adequate job representing the effects of low-order wavefront error, and this may be sufficient for many purposes, for example in optimization of optical design.

\section{Discussion}
\label{sec:discussion}

A phase transfer matrix constructed analytically with a discrete pupil model contains no a priori information about the pixel sampling, binning, or windowing. This means that the implicit convolutions in the $u,v$ plane, and therefore the associated correlation between adjacent baselines, is not taken into account.  Therefore the normally-orthonormal kernel phases (calculated analytically for an infinite field of view and fine sampling) are no longer fully linearly independent. For example \citet{martinache20} notes that in the analysis of \citet{palomar}, windowing to avoid the ghost introduced by a neutral density filter cuts the number of pixels to less than the number of kernel phases, so that information is being lost. \citet{martinache20} also demonstrates the utility of a detailed model of pupil (mis-)alignment to improve the extraction of both kernel phase and visibility information.

The non-independence of kernel phases has been treated statistically by \citet{ireland13}, who uses principal component analysis applied to an ensemble of kernel phase observations to extract statistically-independent kernel phases. When the advantage of kernel phase is knowing that some combinations of phases have high signal-to-noise \textit{a priori}, it would be preferable to avoid this situation with a better kernel phase construction rather than calibration.

A further issue is that the $u,v$-plane calculation of earlier kernel phase work suffers from discretization noise from interpolating the FFT. This can be ameliorated by using a matrix Fourier transform adapted to the wavelength and exact pupil model \citep{martinache_habilitation}.

By calculating kernel phases from differentiating an end-to-end optical simulation, even for trivial apertures, the exact pixel grid, including binning, windowing, and dead pixels can be included. As the matrix DFT is already used to calculate the FT, there is no sampling noise to separately incorporate, and all kernel phases are automatically orthonormal.

% forwards model using these matrices a la Pueyo
To avoid self-subtraction, we expect that the best approach to data analysis with kernel phases using these methods will be forwards-modelling the data through the optical system and kernel phase filter along the lines described by \citet{pueyo16} or \citet{martinache20}. These can then be augmented by diversity-based methods along the lines described by \citet{ireland13} to achieve even higher levels of calibration. We have not attempted to use these methods on real data in this paper.

% It will be valuable to consider whether the small difference between the $\alpha$~Ophiuchi binary parameters between this and previous work is due to a differing sensitivity to systematics in one or the other pipeline, or whether due to a flaw in the way the kernel phase matrix is calculated in the autodiff case. Fourier sampling, and numerical noise in the Jacobian, both present the possibility of suboptimal performance, though the method appears to perform well on simulated data.

% other autodiff packages - TensorFlow was slower?
Because of its \textsc{NumPy}-like API, we have used \textsc{jax} to power the automatic differentiation in \textsc{morphine}. We have not extensively optimized this code for fast and memory-efficient autodiff, nor have we benchmarked it against competing frameworks such as \textsC{TensorFlow}. We expect that integration with \textsc{NumPy} and similarity to the existing standard \textsc{poppy} will make \textsc{morphine} more readily useful in astronomy, but for integration with neural networks it may be more convenient to use a different autodiff package. 

\section{Open Science}
\label{sec:open}

In the interests of open science, we have made available the Python package \textsc{morphine}, together with Jupyter notebooks used to generate the figures in this paper, under a BSD 3-clause open source license at \href{https://github.com/benjaminpope/morphine}{github.com/benjaminpope/morphine}. We encourage and welcome other scientists to replicate, apply, and extend our work.

\section{Conclusions and Future Work}
\label{sec:conclusions}

We have shown that automatic differentiation software offers significant benefits to astronomical optics. Using a simple model of diffraction, we can recover the idea of kernel phases, and using real Palomar data we obtain similar astrometric performance to the analytically-derived standard approach. Crucially, this can then be extended to arbitrary systems for which analytic self-calibration may not be possible. We have demonstrated this for a simple Lyot coronagraph, finding a modal basis and kernel observables analogous to kernel phase. Though this may be of limited practical importance due to the strong nonlinearities in the Lyot coronagraph problem, other coronagraphs and imaging systems may derive greater benefit.

In this paper we have shown that autodiff allows us to straightforwardly account for broadband effects as a linear combination of diffraction simulations, which are also differentiable. Likewise, linear mixing of polarization states via Mueller matrices could be included in this framework. This may be important for high angular resolution differential-polarimetry instruments such as SPHERE/ZIMPOL \citep{zimpol} on the VLT, VAMPIRES on the Subaru SCExAO \citep{vampires}, or the GPI polarimeter \citep{gpipol}, where polarization measurements are intrinsic to the goal of the experiment, or to issues with polarization leakage affecting closure phases in holographic aperture masking experiments \citep[e.g.][]{doelman18}.

% wavefront control using the nonsingular space
In high contrast imaging with adaptive optics, a major issue of residual aberration comes from the differing optical paths between the deformable mirror and on the one hand the wavefront sensor, and on the other the science camera. Non-common-path aberrations in this part of the optical system cannot be sensed and corrected inside the AO loop alone. Slowly-evolving non-common path errors cause quasi-static speckles that are one of the key sources of noise limiting the sensitivity of high-contrast instruments to exoplanets. As noted by \citet{martinache13}, the space complementary to kernel phases, which are affected directly by phase noise, can be used for focal-plane wavefront sensing. This has the advantage of avoiding non-common path errors between the wavefront sensor and the science instrument. For a simple aperture, so long as the pupil is not symmetric with respect to inversion around its centre, all pupil phase information is encoded in the PSF and can be recovered reasonably accurately with a Moore-Penrose pseudoinverse of the phase transfer matrix \citep{moore1920,bjerhammar1951,penrose_1955}. This can be made even more effective with an integral field spectrograph, as spectrally-dispersed PSFs encode a hologram of the input wavefront \citep{martinache16}. The asymmetric pupil linear phase transfer approach has been used for focal-plane wavefront sensing in the lab \citep[e.g.][]{pope14,swift} and on Subaru SCExAO \citep{martinache16b}. Extending the domain of applicability of the linear phase transfer paradigm to coronagraphs using autodiff may allow for new approaches to focal plane wavefront sensing. 

The approach of \citet{sitzmann2018} to end-to-end optimization of an optical system has clear relevance to optical astronomy. Going beyond using gradients for phase retrieval \citep{jurling14}, we can envision gradient-based \textit{phase design} for coronagraphs,  for diffractive-pupil telescopes, or for starshades. For example, it may be useful in rapidly finding deformable mirror settings to generate a ``dark hole'' in high-contrast imaging \citep{malbet95}. It may also be useful for diffractive-pupil design: the \textsc{Toliman} space telescope concept \citep{tuthill18,bendek18} aims to use a pupil-plane phase mask to achieve high precision relative astrometry of $\alpha$~Centauri AB to search for exoplanets. Work so far in designing the phase mask has been in optimizing parametrized pupils with respect to the radially-weighted gradient energy of the PSF as a proxy for astrometric precision. It will be in principle possible to calculate the Fisher information for the astrometric precision, and to use this as an objective function for optimizing a non-parametric \textsc{Toliman} pupil. By differentiating with respect to phase in intermediate planes, \textsc{morphine}-like methods will also be useful in intermediate-plane wavefront control and mask design.

%outside of astronomy
The generalization of kernel phase and optical gradient design permitted by autodiff also allows us to extend this work to the near-field (Fresnel) propagation regime. This may lead to improvements in modelling of components (such as deformable mirrors) that might occur in planes intermediate between pupil and focus, or simply more accurate kernel phase models of instruments such as the \textit{Hubble Space Telescope}. This may be most relevant outside of astronomy: for example, Fresnel coherent diffractive imaging \citep{williams2006} is a popular microscopy technique, in which gradient-based advances in phase retrieval have been applied \citep{Dueaay3700}, and kernel phase and optimization may be valuable.

\section*{Acknowledgements} % add your acknowledgements text here!

We would like to thank Anand Sivaramakrishnan, Marshall Perrin, Will Farr, and David Hogg for their very helpful comments.

This work was performed in part under contract with the Jet Propulsion Laboratory (JPL) funded by NASA through the Sagan Fellowship Program executed by the NASA Exoplanet Science Institute. 

This research made use of NASA's Astrophysics Data System.

BJSP acknowledges being on the traditional territory of the Lenape Nations and recognizes that Manhattan continues to be the home to many Algonkian peoples. We give blessings and thanks to the Lenape people and Lenape Nations in recognition that we are carrying out this work on their indigenous homelands.
%
\software{This research made use of \textsc{jax} \citep{jax}; \textsc{poppy}, an open-source optical propagation Python package originally developed for the James Webb Space Telescope project \citep{poppy}; the \textsc{IPython} package \citep{ipython}; \textsc{NumPy} \citep{numpy}; \textsc{matplotlib} \citep{matplotlib} \textsc{SciPy} \citep{scipy}; \texttt{emcee} \citep{emcee} and \texttt{corner.py} \citep{corner}; and Astropy, a community-developed core Python package for Astronomy \citep{astropy}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%


\bibliography{ms}


%% This command is needed to show the entire author+affilation list when
%% the collaboration and author truncation commands are used.  It has to
%% go at the end of the manuscript.
%\allauthors

%% Include this line if you are using the \added, \replaced, \deleted
%% commands to see a summary list of all changes at the end of the article.
%\listofchanges

\end{document}

% End of file `sample62.tex'.
