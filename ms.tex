%%
%% Beginning of file 'sample62.tex'
%%
%% Modified 2018 January
%%
%% This is a sample manuscript marked up using the
%% AASTeX v6.2 LaTeX 2e macros.
%%
%% AASTeX is now based on Alexey Vikhlinin's emulateapj.cls 
%% (Copyright 2000-2015).  See the classfile for details.

%% AASTeX requires revtex4-1.cls (http://publish.aps.org/revtex4/) and
%% other external packages (latexsym, graphicx, amssymb, longtable, and epsf).
%% All of these external packages should already be present in the modern TeX 
%% distributions.  If not they can also be obtained at www.ctan.org.

%% The first piece of markup in an AASTeX v6.x document is the \documentclass
%% command. LaTeX will ignore any data that comes before this command. The 
%% documentclass can take an optional argument to modify the output style.
%% The command below calls the preprint style  which will produce a tightly 
%% typeset, one-column, single-spaced document.  It is the default and thus
%% does not need to be explicitly stated.
%%
%%
%% using aastex version 6.3
\documentclass[modern]{aastex63}

%% The default is a single spaced, 10 point font, single spaced article.
%% There are 5 other style options available via an optional argument. They
%% can be envoked like this:
%%
%% \documentclass[argument]{aastex62}
%% 
%% where the layout options are:
%%
%%  twocolumn   : two text columns, 10 point font, single spaced article.
%%                This is the most compact and represent the final published
%%                derived PDF copy of the accepted manuscript from the publisher
%%  manuscript  : one text column, 12 point font, double spaced article.
%%  preprint    : one text column, 12 point font, single spaced article.  
%%  preprint2   : two text columns, 12 point font, single spaced article.
%%  modern      : a stylish, single text column, 12 point font, article with
%% 		  wider left and right margins. This uses the Daniel
%% 		  Foreman-Mackey and David Hogg design.
%%  RNAAS       : Preferred style for Research Notes which are by design 
%%                lacking an abstract and brief. DO NOT use \begin{abstract}
%%                and \end{abstract} with this style.
%%
%% Note that you can submit to the AAS Journals in any of these 6 styles.
%%
%% There are other optional arguments one can envoke to allow other stylistic
%% actions. The available options are:
%%
%%  astrosymb    : Loads Astrosymb font and define \astrocommands. 
%%  tighten      : Makes baselineskip slightly smaller, only works with 
%%                 the twocolumn substyle.
%%  times        : uses times font instead of the default
%%  linenumbers  : turn on lineno package.
%%  trackchanges : required to see the revision mark up and print its output
%%  longauthor   : Do not use the more compressed footnote style (default) for 
%%                 the author/collaboration/affiliations. Instead print all
%%                 affiliation information after each name. Creates a much
%%                 long author list but may be desirable for short author papers
%%
%% these can be used in any combination, e.g.
%%
%% \documentclass[twocolumn,linenumbers,trackchanges]{aastex62}
%%
%% AASTeX v6.* now includes \hyperref support. While we have built in specific
%% defaults into the classfile you can manually override them with the
%% \hypersetup command. For example,
%%
%%\hypersetup{linkcolor=red,citecolor=green,filecolor=cyan,urlcolor=magenta}
%%
%% will change the color of the internal links to red, the links to the
%% bibliography to green, the file links to cyan, and the external links to
%% magenta. Additional information on \hyperref options can be found here:
%% https://www.tug.org/applications/hyperref/manual.html#x1-40003
%%
%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
% added by DH
\usepackage{xspace}
\usepackage{}

\newcommand{\numax}{\mbox{$\nu_{\rm max}$}\xspace}
\newcommand{\Dnu}{\mbox{$\Delta \nu$}\xspace}
\newcommand{\dnu}{\mbox{$\delta \nu$}\xspace}
\newcommand{\muHz}{\mbox{$\mu$Hz}\xspace}
\newcommand{\teff}{\mbox{$T_{\rm eff}$}\xspace}
\newcommand{\logg}{\mbox{$\log g$}\xspace}
\newcommand{\feh}{\mbox{$\rm{[Fe/H]}$}\xspace}
\newcommand{\msun}{\mbox{$\mathrm{M}_{\sun}$}\xspace}
\newcommand{\mearth}{\mbox{$\mathrm{M}_{\oplus}$}\xspace}

\newcommand{\rsun}{\mbox{$\mathrm{R}_{\sun}$}\xspace}
\newcommand{\hipparcos}{\textit{Hipparcos}\xspace}
\newcommand{\gaia}{\textit{Gaia}\xspace}


\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand\kepler{\emph{Kepler}\,}
\newcommand\ktwo{\emph{K2}\,}

\definecolor{linkcolor}{rgb}{0.1216,0.4667,0.7059}


\usepackage{xcolor, fontawesome}
\definecolor{twitterblue}{RGB}{64,153,255}
\newcommand\twitter[1]{\href{https://twitter.com/#1 }{\textcolor{twitterblue}{\faTwitter}\,\tt \textcolor{twitterblue}{@#1}}}
\usepackage{amsmath}

%% Tells LaTeX to search for image files in the 
%% current directory as well as in the figures/ folder.
\graphicspath{{../notebooks/}}

%% Reintroduced the \received and \accepted commands from AASTeX v5.2
% \received{January 1, 2019}
% \revised{January 7, 2019}
% \accepted{\today}
%% Command to document which AAS Journal the manuscript was submitted to.
%% Adds "Submitted to " the arguement.
% \submitjournal{ApJ}

%% Mark up commands to limit the number of authors on the front page.
%% Note that in AASTeX v6.2 a \collaboration call (see below) counts as
%% an author in this case.
%
%\AuthorCollaborationLimit=3
%
%% Will only show Schwarz, Muench and "the AAS Journals Data Scientist 
%% collaboration" on the front page of this example manuscript.
%%
%% Note that all of the author will be shown in the published article.
%% This feature is meant to be used prior to acceptance to make the
%% front end of a long author article more manageable. Please do not use
%% this functionality for manuscripts with less than 20 authors. Conversely,
%% please do use this when the number of authors exceeds 40.
%%
%% Use \allauthors at the manuscript end to show the full author list.
%% This command should only be used with \AuthorCollaborationLimit is used.

%% The following command can be used to set the latex table counters.  It
%% is needed in this document because it uses a mix of latex tabular and
%% AASTeX deluxetables.  In general it should not be needed.
%\setcounter{table}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section outlines numerous optional output that
%% can be displayed in the front matter or as running meta-data.
%%
%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
\shorttitle{Kernel Phase and Coronagraphy with Automatic Differentiation}
\shortauthors{B. J. S. Pope}
%%
%% You can add a light gray and diagonal water-mark to the first page 
%% with this command:
% \watermark{text}
%% where "text", e.g. DRAFT, is the text to appear.  If the text is 
%% long you can control the water-mark size with:
%  \setwatermarkfontsize{dimension}
%% where dimension is any recognized LaTeX dimension, e.g. pt, in, etc.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is the end of the preamble.  Indicate the beginning of the
%% manuscript itself with \begin{document}.

\begin{document}

\title{Kernel Phase and Coronagraphy with Automatic Differentiation}

\correspondingauthor{Benjamin J. S. Pope \twitter{fringetracker}}
\email{benjamin.pope@nyu}

\author[0000-0003-2595-9114]{Benjamin J. S. Pope}
\affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY 10003, USA}
\affiliation{Center for Data Science, New York University, 60 Fifth Ave, New York, NY 10011, USA}
\affiliation{NASA Sagan Fellow}

%% Mark off the abstract in the ``abstract'' environment. 
\begin{abstract}
% optical imaging with aberrations
Aberrations in the optical path introduce distortions and speckles in the resulting images which limit the performance of cameras at high angular resolution.

% self cal - closure phase and kernel phase
Self-calibrating observables such as the `closure phase' or `bispectrum' have been widely used in optical and radio astronomy to correct for this: a linear combination of measurements with phase noise can be made such that error terms cancel, leaving a subspace of high signal-to-noise observables. Kernel phases are a generalization of closure phases, in which the effect of aberration on an arbitrary pupil is approximated as a linear phase transfer matrix.

%coronagraphs are hard
Finding this operator is analytically tractable between a single pupil and focus but is much more difficult for other optical systems of interest, such as coronagraphs.
% autodiff can make this practical for arbitrary optical systems
Automatic differentiation or `backpropagation' software now makes calculating derivatives with respect to aberrations in arbitrary planes straightforward for any optical system.

% we demonstrate a simple example of the kernel of a monochromatic coronagraph
We reproduce existing kernel phase theory within this framework and demonstrate an extension to the case of a Lyot coronagraph, which is found to have self-calibrating combinations of speckles which are resistant to phase noise, but only in the very high wavefront quality regime. We also use this framework to reanalyze Palomar adaptive optics observations of the binary $\alpha$~Ophiuchi, finding broad consistency and slight systematics between the new pipeline and the existing standard.

%phase design
We present a Python package \textsc{morphine}, with an interface similar to the popular package \textsc{poppy}, for optical simulation with automatic differentiation. These methods may be useful for designing improved astronomical optical systems by gradient descent.
\href{https://github.com/benjaminpope/morphine}{\color{linkcolor}\faGithub} % shamelessly borrowed from Luger!

\end{abstract}

%% Keywords should appear after the \end{abstract} command. 
%% See the online documentation for the full list of available subject
%% keywords and the rules for their use.
% \keywords{editorials, notices --- 
% miscellaneous --- catalogs --- surveys}


\section{Introduction} 
\label{sec:intro}
% optical imaging with aberrations
Many questions in astronomy and other sciences can only be answered with diffraction-limited high resolution imaging. The highest resolutions are typically achieved with the method of interferometry, in which waves detected at multiple receivers are combined physically or in post-processing to obtain the Fourier transform of the source intensity distribution \citep{vc34,zernike38}. Even in the case of a single telescope or camera, it is often nevertheless helpful to think of them as an interferometer composed of many sub-apertures which combine their signals directly onto a focal plane \citep[a `Fizeau interferometer':][]{fizeau1868}}. In all of these cases, unknown path delays toward each receiver or subaperture are a dominant source of noise, causing `tip-tilts' of the final image position, distortions of the point spread function (PSF) from low-spatial-frequency aberrations, and clouds of `speckles' from high-spatial-frequency aberrations.

% self cal with closure phase
The traditional answer to this has been self-calibration with `closure phases' \citep[introduced in the context of radio astronomy by][]{jennison58}}, in which phases are added around three interferometric baselines which form a closing triangle. The phase error terms local to each subaperture cancel, so that you trade three low-signal-to-noise (SNR) baseline phases for one high-SNR observable. In a non-redundant array (one in which no baseline is repeated between different pairs of subapertures) of sufficient size, a large number of closure phases can be obtained which anchor image reconstruction with great precision. `Closure amplitudes' which are resistant to fluctuations in input amplitude or gain can also be obtained by a similar construction using four telescopes \citep{twiss60}. The closure phase is the argument of a quantity called the triple product or `bispectrum', and it has recently been shown from the perspective of invariant theory in algebraic geometry that for a wide class of problems limited by phase noise, knowledge of the mean, power spectrum and bispectrum are necessary and sufficient for an optimal signal reconstruction \citep{bandeira17}.

On the other hand, in exoplanet direct imaging with coronagraphs, analytic self calibrations such as this are not yet known. The standard approaches to data analysis in coronagraphy rely on exploring a diversity of PSFs experimentally, constructing a basis covering some of the diversity in speckle patterns, and then subtracting out a linear combination of vectors in this basis from measured data \citep[e.g.][]{lafreniere07,soummer12,pueyo16}}. Advantages can also be gained from angular differential imaging \citep[ADI;][]{marois06}} and spectral deconvolution with wavelength \citep{sparks02}. In this paper we will extend our understanding of analytic self calibration to better include coronagraphs, so that we can add an additional layer of precision to exoplanet imaging calibration.

\subsection{Kernel Phases}

% introduce kernel phase idea
The kernel phase method is a way of extending closure phase from simple nonredundant arrays of telescopes to the densely-filled pupils of real telescopes. If we describe the propagation of phase and amplitude noise in terms of a matrix \citep{lannes1991}, we can obtain powerful generalizations to closure phases and amplitudes. We then write

\begin{equation}
    \mathbf{\Phi} = \mathbf{\Phi}_0 + \mathbf{A}_\phi \cdot \phi,
\end{equation}

\noindent where $\mathbf{\Phi}$ is a vector of observed phases on each baseline in the $u,v$ (focal plane Fourier domain), $\mathbf{\Phi}_0$ the true astrophysical phases, $\phi$ the phase noise at each point in the pupil plane, and $\mathbf{A}_\phi$ a transfer matrix from the pupil plane to the $u,v$ plane phases. A similar expression can be written for amplitudes \citep{pope16}.  Even for a redundant aperture such as a standard full telescope pupil, for sufficiently small phase perturbations ($<< 1~\text{rad}$), error propagation to the focal plane Fourier phases is still approximately linear: this is simply a Taylor expansion to first order of the nonlinear phase transfer operation, in which $\mathbf{A}_\phi$ is the Jacobian matrix of partial derivatives $\partial\Phi_j/\partial\phi_k$. For a single focal plane imaging system this operator $\mathbf{A}_\phi$ can be determined analytically for a given discrete pupil model. 

\citet{martinache10} introduced the idea of `kernel phase', suggesting that while for a redundant aperture closure phases no longer cancel out the contributions of aberrations $\phi$, nevertheless in general a left kernel operator $\mathbf{K}$ can be found via singular value decomposition (SVD) of $\mathbf{A}_\phi$ such that

\begin{equation}
        \mathbf{K}\cdot\mathbf{A}_\phi = 0
\end{equation}

\noindent and therefore we can find self-calibrating kernel phases $\mathbf{K}\cdot\mathbf{\Phi}$ which are immune to phase noise to linear order:

\begin{align}
    \mathbf{K}\cdot\mathbf{\Phi} &= \mathbf{K}\cdot\mathbf{\Phi}_0 + \mathbf{K}\cdot\mathbf{A}_\phi\cdot\phi \\
    &= \mathbf{K}\cdot\mathbf{\Phi}_0.
\end{align}

Meanwhile, the phases in the complementary space to the kernel space have the opposite property, that they are especially sensitive to input phase aberrations, and for appropriate apertures can be used for wavefront sensing from the image domain \citep{martinache13,pope14}.

The kernel phase method has been applied to space-based data from the \textit{Hubble Space Telescope} NICMOS camera \citep{pope13,laugier19,martinache20}; ground-based data from the Palomar 200-Inch adaptive optics (AO) equipped Pharo camera \citep{palomar,martinache20}, the Large Binocular Telescope \citep{sallum15}, the VLT/NACO camera \citep{kammerer19}, MagAO \citep{sallum19b}, and explored theoretically for ground- and space-based telescopes \citep{ireland13,martinache11,sallum19a,ceau19}.

% coronagraphs, speckles etc
It is desirable to find a priori self-calibration schemes for high-angular-resolution, high-contrast imaging systems more generally, including not merely nulling interferometers but optically complex coronagraphs, which block out light in a region around a target star. One particularly interesting extension of the kernel phase idea is the `kernel nuller' concept \citep{martinache18}, in which the aberration transfer matrix and kernel operator idea is applied to the output of a nulling interferometer. 

For arbitrary systems, to generate our Taylor expansion, we wish to be able to take the Jacobian of arbitrary features of the final speckle pattern with respect to phases in the input wavefront or in intermediate planes. This could then be used in postprocessing to generate `kernel speckles' resistant to noise, or in wavefront control for adaptive optics, or for digging `dark holes' to search for high contrast companions \citep{malbet95}.

Arbitrary-order Taylor series expansions for a PSF with respect to small phase perturbations can be derived analytically for a telescope with an arbitrary pupil brought to a single focus \citep{bloemhof01,anand02,perrin03}. This expansion breaks down for more complex optical systems. The PSF of a coronagraphic imager far from the occulted region is very similar to that of the primary PSF of the telescope, but close to the inner working angle it is significantly affected by the occultation and especially strongly by low-order wavefront errors. This is likewise an issue where detector nonlinearity and saturation significantly distort the PSF. While the analytic series expansion is no longer applicable in these regimes, using matrix Fourier transforms and skipping saturated pixels or pixels inside the coronagraphic inner working angle has shown promise for pushing kernel phase beyond its conventional limitations \citep{laugier19b}, as have generalizations that exploit angular differential imaging for a further level of calibration \citep{laugier20}.

We shall see in the following that automatic differentiation can supply these missing derivatives for arbitrary numerically-simulated imaging systems.

\subsection{Automatic Differentiation}
% autodiff/backpropagation - history & citations
The practical use of neural networks in machine learning applications is dependent on the efficient calculation of analytic gradients of often very complicated composite functions, for example the matrix operations composed with nonlinear activation functions that are seen in neural networks \citep{lecun15}. This problem is usually referred to as algorithmic differentiation, automatic differentiation or `autodiff', and is solved simply by the chain rule.
Autodiff is available in many implementations, such as the Python packages \textsc{TensorFlow} \citep{tensorflow2015}, \textsc{theano} \citep{theano}, \textsc{PyTorch} \citep{pytorch}, \textsc{autograd} \citep{autograd}, \textsc{jax} \citep{jax}, and many packages in the Julia language \citep{julia}. The reverse-mode autodiff or `backpropagation' algorithm \citep{linnainmaa1970,lecun1988theoretical} has made this practical for neural networks, but it is typically most-useful in cases where the output dimensionality is much smaller than the input, such as neural networks; forwards-mode autodiff, on the other hand, is usually better in the case where the output is of higher dimension than the input. For optics problems, both of these can be the case - for example, for optimization, backpropagation is usually the best approach, but for kernel phase analysis, forwards mode is better suited.

% optics is linear and nonlinear relations between quantities eg phase consist entirely of elementary operators that can be differentiated like in a neural network
In simulating physical optics, we normally consider the complex electric field on a 2D plane, which is pixelized and then flattened to a 1D vector.
Optical propagation then consists of a series of Fourier (or  Fresnel) transforms mapping between planes, and matrix or element-wise multiplications by phase and amplitude screens in those planes. Indeed, for practical purposes in astronomy and imaging science generally, optical propagation through a whole system is generally a linear operation that could be written as a single (large) matrix multiplication. However quantities of interest are usually not specified as real and imaginary electric field components, but rather as amplitudes and phases, so that the relations between (for example) input and output phases is in general nonlinear. Finding the derivatives of $u,v$ phase with respect to pupil aberrations is therefore an ideal problem for autodiff.

The analogy between the operations of optics and deep neural networks is so strong that not only have autodiff packages been used to simulate photonic systems \citep[e.g.][]{hughes18}, photonic systems have in fact been used as analog computers implementing neural networks for machine learning \citep{hughes19,guo19}. 

Several groups have applied autodiff to areas of optical science relevant to astronomy. Autodiff has been applied fruitfully to geometric optics or ray-tracing \citep[e.g.][]{werner2012,sutin16}, which is important in astronomy for understanding gravitationally-lensed systems. \citet{chianese19} and \citet{morningstar19} have applied this method to integrating differentiable forwards models of gravitational lensing with neural networks for image analysis. Autodiff methods have also been applied for image reconstruction from interferometric data, including gravitationally-lensed systems \citep{morningstar18} and protoplanetary disks \citep{czekala19}.

The \textsc{DeepOptics} project \citep{sitzmann2018} has used autodiff to optimize `computational cameras'. Building their model in \textsc{TensorFlow}, they couple a physical optics simulation, detector simulation, and a deconvolution post-processing stage for a total end-to-end imaging simulation. Where normally you might optimize some heuristic of the PSF (such as the full width at half maximum), this makes it possible to jointly optimize hardware and software with respect to figures of merit of the overall system such as final resolution or depth of field. Some designs this way are exotic: for example, super-resolution is achieved by finding a lens with three off-centre Fresnel-lens components focusing to three separate spots, which the deconvolution stage shifts and stacks. Because it is built in \textsc{TensorFlow}, the diffraction simulation can be incorporated as a `physical layer' in neural network applications in microscopy, for example for optimizing hardware and software for image classification \citep{muthumbi19}, or with reinforcement learning for adaptively learning sample illumination \citet{chaware19}.

An approach similar to \textsc{DeepOptics} is likely to be extremely valuable in designing, for instance, pupil masks for coronagraphy \citep[e.g.][]{guyon03,carlotti11} or for diffractive-pupil astrometry \citep[e.g.][]{guyon12,tuthill18}. 

Close to the topic of this paper, autodiff has been applied to the problem of phase retrieval \citep{jurling14,paine19}, inferring a wavefront from a PSF. In this context, a key advance of autodiff over previous methods is that we can trivially account for pixel sampling/binning and detector nonlinearity. These will be important issues when considering that the JWST mid-infrared imager MIRI will have significant detector nonlinearity \citep{rieke15}, or where we may wish to look at saturated sources.  While they do not address more complex optical systems, this method may be straightforwardly applicable to sensing non-common-path errors in coronagraphic images. While \citet{jurling14} derive analytic expressions for many optically-relevant operations, machine-learning software that has become available since then have significantly widened the range of options and introduced more user-friendly APIs. These approaches have been taken up outside of optical imaging, for example in X-ray coherent diffractive imaging \citep{kandel19,nashed19} and nanotomography \citep{Dueaay3700}.

Rather than using these autodiff gradients for optimization, in this paper we want to use them to understand optical systems and the information they propagate.
In the following we will show how autodiff can reproduce the existing state of the art in kernel phase, and demonstrate a way forward using autodiff to extend the kernel phase idea to coronagraphic instruments.

\section{Simulations}
\label{sec:method}

For our forwards model, we adapt the popular physical optics library \textsc{poppy} \citep{poppy}, with the goal of compatibility with existing simulations built on \textsc{poppy} such as \textsc{WebbPSF} \citep{webbpsf}. We use the matrix Fourier transform mode to avoid using the FFT \citet{soummer07}, which is more efficient for autodiff applications. We have adapted the low-level features of \textsc{poppy} to use the Google autodiff library \textsc{jax} \citep{jax} in place of \textsc{NumPy}, and to distinguish it from the original version we call this new \textsc{poppy} derivatives library \textsc{morphine}. %The \textsc{NumPy}-like API of \textsc{jax} is chosen so that astronomers can painlessly integrate \textsc{morphine} with their existing code, but we note that a \textsc{DeepOptics}-like approach using \textsc{TensorFlow} may be preferable in the longer term for integration with neural networks. 

This has several advantages already over analytic methods for kernel phase. \textsc{morphine} can calculate monochromatic or polychromatic PSFs: the polychromatic capability allows us to explicitly construct broadband kernel phase operators. It is also possible to take derivatives with respect to wavefronts specified in bases other than the pixel basis, for example Zernike or hexike modes, as we shall discuss in Section~\ref{zernike}.

\subsection{Simple Diffraction}
\label{sec:simple}

First we want to reproduce the basic kernel phase calculations in this new model. We propagate monochromatic 2.0\,$\mu$m light through a 2.0\,m diameter circular pupil onto a detector with a 20\,mas/pixel scale and 4\,arcsec field of view. The pupil and $u,v$ are each calculated on a 64x64 grid. We evaluate the Jacobian of the $u,v$ phases with respect to the input pupil phases using forwards-mode autodiff and then evaluate this Jacobian at zero phase to get our $\mathbf{A}$ matrix\footnote{\href{https://github.com/benjaminpope/morphine/blob/master/notebooks/morphine_u,v.ipynb}{github.com/benjaminpope/morphine/blob/master/notebooks/morphine\_u,v.ipynb}}. On a laptop computer this takes $\sim$ a few minutes. Memory usage is the main overhead here: in practice on a laptop with 16GB RAM, we are limited to grids no larger than 128x128. This is probably the most major limitation of the method; in future it may be overcome by more efficient refactoring of the code, or simply by doing calculations on clusters with very large RAM allocations.

It is inefficient to calculate this full Jacobian with respect to a densely-pixelized basis for the wavefront in the pupil plane, but we do so here for completeness: in practical cases, aberrations are typically dominated by low-order modes and we could consider the Jacobian only with respect to (for example) some much smaller number of Zernike modes. Reducing the input dimensionality like this would have significant advantages in memory using for forwards-mode autodiff.

In Figure~\ref{kernel_jacobian} we display the results of our Jacobian calculation for a set of highlighted baselines, showing side by side on the left a baseline superimposed on the support of the optical transfer function (OTF)\footnote{The OTF is the autocorrelation of the pupil, and is in this case also a circle. Its support is calculated by calculating a $u,v$ forwards model with zero phase offset and making an amplitude-threshold mask.}, and on the right next to it a map of the corresponding Jacobian vector (arranged in 2D). This is the transfer matrix $\mathbf{A}_\phi$ arranged row by row.  

The results are similar to Figure~1 of \citet{martinache10}, consisting of the sums of translated positive and negative copies of the pupil aperture. Phase offsets outside the support of the pupil have identically zero derivative in the $u,v$ plane as expected. There is a greater magnitude in the derivative at longer baselines compared to the flat maps in \citet{martinache10} because we are rolling together the phase transfer $\mathbf{A}$ matrix and the redundancy matrix $\mathbf{R}$, and short baselines are much more redundant than long ones.

We calculate the singular values of this matrix (restricted to the support of the pupil) by SVD (Figure~\ref{fig:svd}), finding a sharp cutoff as expected, separating a subspace of kernel phases from phases contaminated by noise from the aberrations. In the nonsingular space, a selection of pairs of corresponding modes in the pupil and $u,v$ plane are displayed in Figure~\ref{nonsingular_modes}, and a selection of kernel phase modes in the $u,v$ plane are shown in Figure~\ref{kernel_modes}. These illustrate an important point: at the edges of the pupil/long baselines there is extra noise. Because of the limited field of view, noise from outside the pupil or OTF is convolved inside, and large elements in the transfer matrix can dominate parts of the SVD. For numerical stability we have therefore excluded the very longest baselines in calculating kernel phases, but it would be preferable to use a more robust SVD that is tolerant of outliers. This effect is not purely a problem with these simulations: this windowing is a common feature of real data: we need to account for the introduction of noise from outside the OTF to correctly calculate kernel phases, as the normal formalism is exact only in the limit of an infinite field of view. 

\begin{figure}
\plotone{jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for monochromatic 2$\mu$m diffraction from a 2.0\,m diameter circular pupil. In each pair of images, on the left is the support of the optical transfer function (OTF), with a red dot highlighting the selected baseline; on the right is a map of the corresponding baseline's derivative with respect to phase over the pupil. We see the same maps as in Figure~1 of \citet{martinache10}. \label{kernel_jacobian}}
\end{figure}

\begin{figure}
    \plotone{kerphi_singular.pdf}
     \caption{Log-scale plot of the singular values of the phase transfer matrix versus index for simple monochromatic diffraction (blue), 20\% bandwidth (green). Singular values are normalized to the first singular value. In both cases, there is a sharp cutoff separating significant singular values from a subset within machine precision of zero. The vectors corresponding to these approximately zero singular values span the null space of the phase transfer operator, and correspond to kernel phases.}
    \label{fig:svd}
\end{figure}

\begin{figure}
\plotone{nonsingular_modes_mono.pdf}
\caption{Pairs of nonsingular vectors in the pupil and $u,v$ planes from the SVD of the Jacobian in ~\ref{kernel_jacobian}. Some of these orthonormal basis vectors resemble Zernike modes, and all show some ringing structure at the edges of the pupil and OTF support.
\label{nonsingular_modes}}
\end{figure}

\begin{figure}
\plotone{kernel_modes_mono.pdf}
\caption{Some kernel phase maps - singular vectors in the $u,v$ plane from the SVD of the Jacobian in ~\ref{kernel_jacobian}. There is little apparent structure in these.
\label{kernel_modes}}
\end{figure}

We have also repeated the above calculations for light with a $20\%$ fractional bandwidth\footnote{\href{https://github.com/benjaminpope/morphine/blob/master/notebooks/morphine_u,v_broadband.ipynb}{github.com/benjaminpope/morphine/blob/master/notebooks/morphine\_u,v\_broadband.ipynb}}, with a uniform spectrum sampled ten times from $1.8\,\mu\text{m}$\,---\,$2.2\,\mu\text{m}$. The results are very similar, except that the Jacobian maps equivalent to Figure~\ref{kernel_jacobian} are slightly blurred. In the shape of the singular value curve between the broadband and monochromatic cases, a qualitatively similar behaviour is found, although the broadband case has slightly fewer kernel phases and a flatter roll-off.

\subsection{$\alpha$~Ophiuchi}
\label{sec:palomar}

We now apply the new kernel phase formalism to real data: the A-star $\alpha$~Ophiuchi. It was observed with the Palomar~200-Inch telescope, using the extreme adaptive optics system PALM-3K and the PHARO camera. These data were first analyzed by \citet{palomar}, but \citet{martinache20} showed that there was an error in the pupil model used for the original analysis: the pupil was in fact rotated 2 degrees. Using a more accurate pupil model and the updated `xara' kernel phase code, \citet{martinache20} obtained astrometry of separation $\rho = 123.5 \pm 2.9$~mas, position angle $\theta = 86.5 \pm 0.2$~degrees, and contrast $c = 25.1 \pm 1.1$. We therefore seek to recreate this new analysis using autodiff.

We first build a high resolution model of the PHARO pupil using the same code as \citet{martinache20}, and bin it down to a $64\times64$ pixel grid so that pixel values $\in [0,1]$ indicate the fraction of the telescope aperture filling that binned pixel. We then propagate monochromatic 2.145\,$\mu$m light through this onto a $64\times64$-pixel image plane, and use a matrix Fourier transform to map this onto a $u,v$ plane of the same size. We differentiate this using the forwards mode autodiff as above, obtaining the Jacobian shown in Figure~\ref{pharo_jacobian}, and calculate a kernel phase transfer matrix.

\begin{figure}
\plotone{pharo_jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for the PHARO pupil in $K$-band. In each pair of images, on the left is the support of the optical transfer function (OTF), with a red dot highlighting the selected baseline; on the right is a map of the corresponding baseline's derivative with respect to phase over the pupil. We see the same maps as in Figure~1 of \citet{martinache10}. \label{pharo_jacobian}}
\end{figure}

We then extract kernel phases from both $\alpha$~Oph and a point source calibrator $\eps$~Her using a version of \textsc{xara} modified to use the \textsc{morphine} matrix FT in place of its own. Following \citet{martinache20}, we choose as our observables the median kernel phases across all 100 exposures for each, and the standard error of the mean as our base uncertainty on each. To calibrate the kernel phases, we simply subtract those of the calibrator from $\alpha$~Oph and add their uncertainties in quadrature. 

To see the effect of the `ghost' introduced by the neutral density filter used to observe such bright stars, we calculate kernel phase `colinearity' maps as in \citet{martinache20}, shown in Figure~\ref{colinearity}. In these maps we can see that the filter ghost shows up strongly as a false binary in the uncalibrated kernel phase maps, but calibrated kernel phases easily remove this and reveal the tight $\alpha$~Oph binary.


\begin{figure}
\plotone{colinearity_alphaoph.pdf}
\caption{Kernel phase colinearity maps showing the match of a binary model (pale is a better match) to the kernel phase signals from uncalibrated $\alpha$~Oph data (left), the calibrator $\eps$~Her (middle), and calibrated data (right). They closely resemble the maps in Figure~8 of \citet{martinache20}. We can see that in uncalibrated data the filter ghost is clearly visible, but in calibrated data we extract the $\alpha$~Oph binary with no effect from the ghost. \label{colinearity}}
\end{figure}

We then use Markov Chain Monte Carlo \citep{metropolis53} to sample from the posterior assuming Gaussian likelihoods, using the \texttt{emcee} affine-invariant ensemble sampler \citep{emcee}. We obtain binary parameters of separation $\rho = 115.3 \pm 1.2$~mas, position angle $\theta = 85.6 \pm 0.27$~degrees, and contrast $c = 26.3 \pm 0.6$: these are close to the \citet{martinache20} figures, but differ by much more than their small uncertainties. For comparison, the contrast ratio of the system is expected from resolved imaging to be $28.0 \pm 8.3$ in $K$-band \citep{hinkley11}. Posteriors for both inferences are shown in Figure~\ref{comparison_posterior}. 

\begin{figure}
\plotone{comparison_posterior.pdf}
\caption{Posterior distributions for the binary parameters of $\alpha$~Ophiuchi as determined by the autodiff pipeline (black) and the \citet{martinache20} implementation (blue). Corner plots produced by \texttt{corner.py} \citep{corner}. \label{comparison_posterior}}
\end{figure}

In order to investigate this discrepancy, we generated a grid of forwards models. Using the same code used to produce the kernel phase autodiff model, we generated input wavefronts with 20 Zernike modes of aberrations, each with random amplitudes normally-distributed with 15\,nm standard deviation, for a total peak-to-peak amplitude of 206\,nm. These were then shifted and added to simulate a range of binaries at different configurations and contrasts, and both the \citet{martinache20} pipeline and the autodiff pipeline used to retrieve their parameters. The results are shown in Figure~\ref{method_comparison_ensemble}. The pipelines achieve broadly comparable performance on these simulations, with the \citet{martinache20} method being slightly better at closer separations and higher contrasts and autodiff performing marginally better at larger separations. For simulated data with fiducial $\rho = 125$\,mas, $\theta=86^\circ$, and $c = 25$, there is no sign of the systematic difference seen in real data. In \citet{martinache20} a large error term was added in quadrature in order to account for additional noise in the data unexplained by the diversity over exposures and uncalibrated by the kernel phase model. In order to achieve $\chi^2 = 1$ for simulated data, an order of magnitude less additional error was needed in quadrature using both models.

\begin{figure}
\plotone{method_comparison_ensemble.pdf}
\caption{Comparison of \citet[][blue stars]{martinache20} and autodiff (orange dots) kernel phase pipelines on simulated data, as a function of input contrast (left) and separation (right). When inspected, the samples with worse separation error after both pipelines are those at higher contrasts. Uncertainties are omitted for clarity, and because they are poorly defined in this context. \label{method_comparison_ensemble}}
\end{figure}

In numerical experiments, subpixel mismatch in Fourier transform coordinates or even Fourier centering convention could cause mismatches between simulation paramet and retrievals at around the scale of the mismatch between the two methods.  These results are in line with the \citet{martinache_habilitation} conclusion that inexact Fourier sampling contributes significant systematic noise to kernel phases.The final version used for the autodiff pipeline uses the exact optical model used to generate the data, and a differentiable version of the exact $u,v$ transform implementation used in \textsc{xara}; we do not believe this to be the main cause of the small discrepancy between autodiff and conventional parameters, but it does illustrate that model mis-specification may be a contributing factor.

\subsection{Coronagraphy}
\label{sec:coronagraph}

We now consider a very simple Lyot coronagraph \citep{lyot30}, using \textsc{morphine}. We choose a 1\,$\mu$m wavelength, and 1\,m diameter pupil sampled on a $64\times64$ grid. The central $4 \lambda/D$ region of the resulting PSF is blocked out with a focal plane stop, and the light is then propagated to a second pupil plane using an FFT rather than a matrix FT, following standard \textsc{poppy} practice; this imposes tougher memory constraints, and in future may be replaced with an MFT. A Lyot stop (a pupil mask undersized 10\% relative to the input pupil) is then imposed, and the light is propagated to a final focal plane sampled on a 50\,mas pixel scale grid with a 4~arcsec field of view. Aside from the coarse gridding, this is intentionally identical to one of the standard example pieces for \textsc{poppy}\footnote{\href{https://github.com/mperrin/poppy/blob/master/notebooks/MatrixFTCoronagraph_demo.ipynb}{github.com/mperrin/poppy/blob/master/notebooks/MatrixFTCoronagraph\_demo.ipynb}}, for the sake of consistency. The PSF produced has a dark coronagraphic hole in the middle, and beyond an inner working angle around this hole has a nearly normal Airy pattern of diffraction rings.

Again using \textsc{jax}, we calculate the Jacobian of this PSF with respect to the input wavefront, evaluated at uniform-zero phase, which again takes a few minutes on a laptop. The previous approach has been to directly propagate through the end to end simulation for a grid of small perturbations in the input plane \citep{falco}, whereas this is now taken care of by autodiff. The results are displayed in Figure~\ref{speckle_jacobian} in a similar format to Figure~\ref{kernel_jacobian}. Pixels far out in the PSF correspond to sinusoidal modulation of the input wavefront exactly as expected, and this is symmetric about the origin. On the other hand, pixels near the inner working angle where the effects of the coronagraph are evident correspond to interestingly-shaped modes in the pupil, and contain contributions from the part of the primary pupil that is obscured by the Lyot stop when the pupil is re-imaged. 

Calculating the SVD of this Jacobian (again restricted to the support of the primary pupil) we se that unlike in the case of the simple diffraction, there is not a sharp cliff but instead a rolling-off which nevertheless reaches very small singular values. The singular value curve is displayed in Figure~\ref{fig:svd} in orange. 

\begin{figure}
\plotone{speckle_jacobian.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for a simple Lyot coronagraph. In each pair of images, on the left is the speckle pattern, with a red dot highlighting the selected pixel; on the right is a map of the corresponding pixel's derivative with respect to phase over the pupil. Speckles far from the central dark hole correspond simply to sinusoids across the pupil, while speckles near the inner working angle correspond to more complicated patterns. \label{speckle_jacobian}}
\end{figure}


\begin{figure}
\plotone{nonsingular_modes_corona.pdf}
\caption{Pairs of nonsingular vectors in the pupil and image planes from the SVD of the coronagraph Jacobian in~\ref{speckle_jacobian}.
\label{nonsingular_corona}} 
\end{figure}

\begin{figure}
\plotone{kernel_modes_corona.pdf}
\caption{Some kernel phase maps - damped (nearly-singular) vectors in the image plane from the SVD of the coronagraph Jacobian in~\ref{speckle_jacobian}. There is little apparent structure in these except for weak patterns around the occulted region.
\label{kernel_corona}}
\end{figure}

% As the singular values here do not drop exactly to zero, we verify numerically that these really do span a kernel space of the coronagraph operation. We therefore calculate PSFs corresponding to each wavefront shape in the pupil domain SVD space, for peak amplitude 0.001~rad, 0.01~rad, and 0.1~rad. In Figure~\ref{fig:mads}, we show the median absolute deviation between an unaberrated reference PSF calculation and these simulations, as a function of SVD index. Dotted lines show where the normalized singular values drop below 0.5 (the beginning of the `roll-off' region), $10^{-4}$ (the kernel), and the beginning of modes under the Lyot stop. 

% For both aberration amplitudes, the effects of these aberrations begin to drop sharply at the roll-off and again at the steeper drop off beginning the kernel proper, and this effect is more pronounced for the smaller aberrations. This behaviour is most likely due to the breakdown of linearity for larger phases.

% \begin{figure}
%     \plotone{coronagraph_mad.pdf}
%     \caption{Median absolute deviation as a function of singular value index, between a reference PSF with no aberration and a PSF calculation with $10^{-3}$~rad (blue), $10^{-2}$ rad (green), and $10^{-1}$ peak phase (orange), and the shape of the corresponding singular vector of the pupil domain. Dotted lines show index 405 where the normalized singular values drop to 0.5 in the `roll-off' region; 441, where the singular values drop below $10^{-4}$ (our proposed kernel space); and index 958 where they hit the flat region corresponding to modes under the Lyot stop.}
%     \label{fig:mads}
% \end{figure}

\begin{figure}
\plotone{speckle_jacobian_zernike.pdf}
\caption{A representation of the Jacobian determined by \textsc{jax} for a simple Lyot coronagraph using a Zernike basis of 200 modes to represent wavefront error. In each pair of images, on the left is the speckle pattern, with a red dot highlighting the selected pixel; on the right is a map of the corresponding pixel's derivative with respect to phase over the pupil. We expect that speckles far from the central dark hole will correspond to sinusoids across the pupil, but in the Zernike basis these appear significantly distorted. \label{speckle_jacobian_zernike}}
\end{figure}

For the coronagraph under consideration, the linear regime may be of limited validity. We take one of the sinusoidal ripples which are the columns of the Jacobian in Figure~\ref{speckle_jacobian}, propagate this through a full optical simulation, and take the difference with respect to an unaberrated PSF. In Figure~\ref{corona_nonlinearity}, we see the effects of a sinusoidal phase ripple in the exactly linear regime, with an 0.1~nm amplitude, and a 5.0~nm amplitude. In the linear regime and where the phase ripple is small, we see that the speckle is positive on one side of the PSF and negative on the other. On the other hand, where the phase ripple is even a few nanometres, we see that the speckles are both positive: an indication of the quadratic term in the Taylor series becoming dominant. This quadratic term involves a rank-3 tensor, of the second partial derivatives of each pixel with respect to the wavefront - and there is no equivalent of a kernel operator for tensors of this dimension. The kernel phase trick will therefore not work straightforwardly in this case, though we suggest that future work may search for a higher-dimensional kernel manifold. 

We have shown that self-calibrating observables exist for coronagraphs. But this nonlinearity argument indicates they may be of limited practical applicability to coronagraphic observations except in the extremely high-wavefront-quality regime. Sub-nanometre precision may nevertheless be achieved in future large space telescopes with high-order deformable mirrors.


\begin{figure}
\plotone{corona_nonlinearity.pdf}
\caption{The effect of a sinusoidal phase ripple on the speckle pattern of the coronagraph in Section~\ref{sec:coronagraph}. Left: sinusoidal phase pattern. Centre left: linear transfer map applied to the sinusoidal phase pattern, showing alternating positive and negative speckles on either side of the centre of the PSF. Centre right: the difference between a full optical simulation with an 0.1~nm amplitude phase ripple with respect to an unaberrated PSF, clearly close to the linear case. Right: the same difference simulation but with a 5~nm amplitude ripple, showing positive speckles on both sides of the detector - the quadratic term. \label{corona_nonlinearity}}
\end{figure}

\subsection{Zernike Basis}
\label{zernike}

Because taking the Jacobian of one large pixel grid by another is expensive in terms of memory, it is desirable to bring down the dimensionality of either the input or target space. One way to do this is to use a Zernike basis to represent the wavefront \citep{zernike34}. One advantage of this is that we can examine only up to a certain order in Zernike polynomials if we believe that wavefront errors are negligible below a certain spatial scale. We can then differentiate just with respect to Zernike coefficients, which is much more computationally efficient and allows us to run simulations on grids that are many times larger than otherwise. Similar bases (eg the `hexike' basis) can be constructed for arbitrary non-circular telescope apertures.

We have re-run the simple diffraction simulation from Section~\ref{sec:simple} with 200 Zernike modes on a $256\times256$ grid, and the coronagraph from Section~\ref{sec:coronagraph} on a $128\times128$ grid using 300 Zernike modes. 

The Jacobian derived from this basis for simple diffraction is an excellent approximation to the full calculation on a grid. Given that in problems such as HST data analysis we believe that PSF variations are dominated by low-order modes \citep{pope13}, this allows us to calculate a larger kernel space with a more accurate pupil model than has previously been possible. 

On the other hand for the coronagraph, while it is a huge advantage in simulation speed and fidelity, we see in Figure~\ref{speckle_jacobian_zernike} that this basis does not accurately represent the high-spatial-frequency sine waves corresponding to speckles far from the core of the PSF. On the other hand, it does an adequate job representing the effects of low-order wavefront error. 

\section{Discussion}
\label{sec:discussion}

A phase transfer matrix constructed analytically with a discrete pupil model does not know a priori about the pixel sampling, binning, or windowing. This means that there is convolution in the $u,v$ planeand therefore correlation between adjacent baselines, which means that the normally-orthonormal kernel phases (calculated analytically for an infinite field of view and fine sampling) are no longer linearly independent. For example \citet{martinache20} notes that in the analysis of \citet{palomar}, windowing to avoid the ghost introduced by a neutral density filter cuts the number of pixels to less than the number of kernel phases, so that information is being lost. \citet{martinache20} also demonstrates how using a detailed model of pupil (mis-)alignment can improve the extraction of both kernel phase and visibility information.

The non-independence of kernel phases has been treated statistically by \citet{ireland13}, who uses principal component analysis applied to an ensemble of kernel phase observations to extract statistically-independent kernel phases. When the advantage of kernel phase is knowing that some combinations of phases have high signal-to-noise \textit{a priori}, it would be preferable to avoid this situation with a better kernel phase construction rather than calibration.

A further issue is that the $u,v$-plane calculation of earlier kernel phase work suffers from discretization noise from interpolating the FFT. This can be ameliorated by using a matrix Fourier transform adapted to the wavelength and exact pupil model \citep{martinache_habilitation}.

By calculating kernel phases from differentiating an end-to-end optical simulation, even for trivial apertures, you can include the exact pixel grid, including binning, windowing, and dead pixels. As the matrix DFT is already used to calculate the FT, there is no sampling noise to separately account for, and all kernel phases are automatically orthonormal.

% forwards model using these matrices a la Pueyo
To avoid self-subtraction, we expect that the best approach to data analysis with kernel phases using these methods will be forwards-modelling the data through the optical system and kernel phase filter along the lines described by \citet{pueyo16} or \citet{martinache20}. These can then be augmented by diversity-based methods along the lines described by \citet{ireland13}, to achieve even higher levels of calibration. We have not attempted to use these methods on real data in this paper.

It will be valuable to consider whether the small difference between the $\alpha$~Ophiuchi binary parameters between this and previous work is due to a differing sensitivity to systematics in one or the other pipeline, or whether due to a flaw in the way the kernel phase matrix is calculated in the autodiff case. Fourier sampling, and numerical noise in the Jacobian, both present the possibility of suboptimal performance, though the method appears to perform well on simulated data.

% other autodiff packages - TensorFlow was slower?
Because of its \textsc{NumPy}-like API, we have used \textsc{jax} to power the automatic differentiation in \textsc{morphine}. We have not extensively optimized this code for fast and memory-efficient autodiff, nor have we benchmarked it against competing frameworks such as \textsC{TensorFlow}. We expect that integration with \textsc{NumPy} and similarity to the existing standard \textsc{poppy} will make \textsc{morphine} more readily useful in astronomy, but for integration with neural networks it may be more convenient to use a different autodiff package. 

\section{Open Science}
\label{sec:open}

In the interests of open science, we have made available the Python package \textsc{morphine}, together with Jupyter notebooks used to generate the figures in this paper, under a BSD 3-clause open source license at \href{https://github.com/benjaminpope/morphine}{github.com/benjaminpope/morphine}. We encourage and welcome other scientists to replicate, apply, and extend our work.

\section{Conclusions}
\label{sec:conclusions}

In this paper we have treated mainly the monochromatic case. It is nevertheless straightforward to include broadband effects as a linear combination of diffraction simulations, which are also differentiable. Likewise, linear mixing of polarization states via Mueller matrices is easily adapted in this framework. This may be important for high angular resolution differential-polarimetry instruments such as SPHERE/ZIMPOL \citep{zimpol} on the VLT, VAMPIRES on the Subaru SCExAO \citep{vampires}, or the GPI polarimeter \citep{gpipol}, where polarization measurements are intrinsic to the goal of the experiment, or to issues with polarization leakage affecting closure phases in holographic aperture masking experiments \citep[e.g.][]{doelman18}.

% wavefront control using the nonsingular space
In high contrast imaging with adaptive optics, a major issue of residual aberration comes from the differing optical paths between the deformable mirror and on the one hand the wavefront sensor, and on the other the science camera. Non-common-path aberrations in this part of the optical system cannot be sensed and corrected inside the AO loop alone. Slowly-evolving non-common path errors cause quasi-static speckles that are one of the key sources of noise limiting the sensitivity of high-contrast instruments to exoplanets. As noted by \citet{martinache13}, the space complementary to kernel phases, which are affected directly by phase noise, can be used for focal-plane wavefront sensing. This has the advantage of avoiding non-common path errors between the wavefront sensor and the science instrument. For a simple aperture, so long as the pupil is not symmetric with respect to inversion around its centre, all pupil phase information is encoded in the PSF and can be recovered reasonably accurately with a Moore-Penrose pseudoinverse of the phase transfer matrix \citep{moore1920,bjerhammar1951,penrose_1955}. This can be made even more effective with an integral field spectrograph, as spectrally-dispersed PSFs encode a hologram of the input wavefront \citep{martinache16}. The asymmetric pupil linear phase transfer approach has been used for focal-plane wavefront sensing in the lab \citep[e.g.][]{pope14,swift} and on Subaru SCExAO \citep{martinache16b}. Extending the domain of applicability of the linear phase transfer paradigm to coronagraphs using autodiff may allow for new approaches to focal plane wavefront sensing. 

The approach of \citet{sitzmann2018} to end-to-end optimization of an optical system has clear relevance to optical astronomy. Going beyond using gradients for phase retrieval \citep{jurling14}, we can envision gradient-based \textit{phase design} for coronagraphs and for diffractive-pupil telescopes. For example, it may be useful in rapidly finding deformable mirror settings to generate a ``dark hole'' in high-contrast imaging \citep{malbet95}. It may also be useful for diffractive-pupil design: the \textsc{Toliman} space telescope concept \citep{tuthill18,bendek18} aims to use a pupil-plane phase mask to achieve high precision relative astrometry of $\alpha$~Centauri AB to search for exoplanets. Work so far in designing the phase mask has been in optimizing parametrized pupils with respect to the radially-weighted gradient energy of the PSF as a proxy for astrometric precision. It will be in principle possible to calculate the Fisher information for the astrometric precision, and to use this as an objective function for optimizing a non-parametric \textsc{Toliman} pupil. By differentiating with respect to phase in intermediate planes, \textsc{morphine}-like methods will also be useful in intermediate-plane wavefront control and mask design.

%outside of astronomy
The generalization of kernel phase and optical gradient design permitted by autodiff also allows us to extend this work to the near-field (Fresnel) propagation regime. This may lead to improvements in modelling of components (such as deformable mirrors) that might occur in planes intermediate between pupil and focus, or simply more accurate kernel phase models of instruments such as the \textit{Hubble Space Telescope}. This may be most relevant outside of astronomy: for example, Fresnel coherent diffractive imaging \citep{williams2006} is a popular microscopy technique, in which gradient-based advances in phase retrieval have been applied \citep{Dueaay3700}, and kernel phase and optimization may be valuable.

\section*{Acknowledgements} % add your acknowledgements text here!

This idea originated in a conversation with Laurent Pueyo and Nour Skaf. I would like to thank them together with Yinzi Xin, Anand Sivaramakrishnan, Marshall Perrin, Will Farr, David Hogg, and Peter Tuthill for their very helpful comments.

This work was performed in part under contract with the Jet Propulsion Laboratory (JPL) funded by NASA through the Sagan Fellowship Program executed by the NASA Exoplanet Science Institute. 

This research made use of NASA's Astrophysics Data System.

BJSP acknowledges being on the traditional territory of the Lenape Nations and recognizes that Manhattan continues to be the home to many Algonkian peoples. We give blessings and thanks to the Lenape people and Lenape Nations in recognition that we are carrying out this work on their indigenous homelands.
%
\software{This research made use of \textsc{jax} \citep{jax}; \textsc{poppy}, an open-source optical propagation Python package originally developed for the James Webb Space Telescope project \citep{poppy}; the \textsc{IPython} package \citep{ipython}; \textsc{NumPy} \citep{numpy}; \textsc{matplotlib} \citep{matplotlib} \textsc{SciPy} \citep{scipy}; \texttt{emcee} \citep{emcee} and \texttt{corner.py} \citep{corner}; and Astropy, a community-developed core Python package for Astronomy \citep{astropy}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%


\bibliography{ms}


%% This command is needed to show the entire author+affilation list when
%% the collaboration and author truncation commands are used.  It has to
%% go at the end of the manuscript.
%\allauthors

%% Include this line if you are using the \added, \replaced, \deleted
%% commands to see a summary list of all changes at the end of the article.
%\listofchanges

\end{document}

% End of file `sample62.tex'.
